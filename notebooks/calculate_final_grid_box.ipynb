{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the final grid box\n",
    "\n",
    "- According to grid search results (See the hierachical clustering gri search notebook) Use the median clustering method with following parameters:\n",
    "\n",
    "     - Standard factor (for the median filter): 100\n",
    "\n",
    "     - pind_weight: 2.5\n",
    "\n",
    "     - Clustering with Kmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data path\n",
    "data_path = \"/Users/nicha/dev/Protein-preparation-pipeline/data/toy_examples_clustering\"\n",
    "\n",
    "# System and OS utilities\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Numerical and Data Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Scientific and Bioinformatics Tools\n",
    "from math import e\n",
    "from pymol import cmd, stored\n",
    "import numpy as np\n",
    "from Bio import PDB\n",
    "from scipy.spatial import distance_matrix, KDTree\n",
    "from scipy.stats import shapiro\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations, product\n",
    "\n",
    "\n",
    "# Machine Learning & Clustering\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import py3Dmol\n",
    "\n",
    "# Color Mapping for Visualization\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import Normalize\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.linalg import eigh\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "\n",
    "# Add project-specific source path\n",
    "sys.path.append('/Users/nicha/dev/Protein-preparation-pipeline/src/')\n",
    "\n",
    "# Custom Modules from Your Project\n",
    "from pdb_retrival.data_retriever import PDBDataRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for the data preparation\n",
    "\n",
    "# 1️⃣ Extract residue coordinates from PDB\n",
    "def extract_residue_coordinates(pdb_file, residue_number, chain_id=\"A\"):\n",
    "    \"\"\"\n",
    "    Extracts atomic coordinates for a given residue from a PDB file.\n",
    "\n",
    "    Args:\n",
    "        pdb_file (str): Path to the PDB file.\n",
    "        residue_number (int): Residue number to extract.\n",
    "        chain_id (str): Chain ID of the residue.\n",
    "\n",
    "    Returns:\n",
    "        list: List of tuples (atom_type, x, y, z).\n",
    "    \"\"\"\n",
    "    coordinates = []\n",
    "    try:\n",
    "        with open(pdb_file, \"r\") as file:\n",
    "            for line in file:\n",
    "                if line.startswith((\"ATOM\", \"HETATM\")) and line[21] == chain_id:\n",
    "                    resi = int(line[22:26].strip())\n",
    "                    if resi == residue_number:\n",
    "                        atom_type = line[76:78].strip()\n",
    "                        x = float(line[30:38].strip())\n",
    "                        y = float(line[38:46].strip())\n",
    "                        z = float(line[46:54].strip())\n",
    "                        coordinates.append((atom_type, x, y, z))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {pdb_file} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "    return coordinates\n",
    "\n",
    "\n",
    "# 2️⃣ Compute Weighted Center of Mass\n",
    "def calculate_weighted_center_of_mass(coordinates):\n",
    "    \"\"\"\n",
    "    Calculates the weighted center of mass for a given set of atomic coordinates.\n",
    "\n",
    "    Args:\n",
    "        coordinates (list): List of tuples (atom_type, x, y, z).\n",
    "\n",
    "    Returns:\n",
    "        list: [x, y, z] coordinates of the weighted center of mass.\n",
    "    \"\"\"\n",
    "    total_weight = 0\n",
    "    weighted_coords = np.zeros(3)\n",
    "    atomic_weights = {\"H\": 1.008, \"C\": 12.011, \"N\": 14.007, \"O\": 15.999, \"S\": 32.06}\n",
    "\n",
    "    for atom_type, x, y, z in coordinates:\n",
    "        weight = atomic_weights.get(atom_type.upper(), 1.0)\n",
    "        weighted_coords += np.array([x, y, z]) * weight\n",
    "        total_weight += weight\n",
    "\n",
    "    return np.round(weighted_coords / total_weight, 3).tolist()\n",
    "\n",
    "\n",
    "# 3️⃣ Process a Single PDB File and Update the DataFrame\n",
    "def process_pdb_file(data_path, pdb_code, df):\n",
    "    \"\"\"\n",
    "    Reads a PDB file and updates a DataFrame with residue center of mass.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): Path to the directory containing the PDB and CSV files.\n",
    "        pdb_code (str): PDB code of the protein.\n",
    "        df (pd.DataFrame): DataFrame containing residue data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with center of mass information.\n",
    "    \"\"\"\n",
    "    pdb_file = os.path.join(data_path, f\"{pdb_code}.pdb\")\n",
    "\n",
    "    try:\n",
    "        for index, row in df.iterrows():\n",
    "            residue_number = row[\"resi\"]\n",
    "            chain_id = row[\"chain\"]\n",
    "            coordinates = extract_residue_coordinates(pdb_file, residue_number, chain_id)\n",
    "            if coordinates:\n",
    "                center_of_mass = calculate_weighted_center_of_mass(coordinates)\n",
    "                df.loc[index, \"resn_coordinates\"] = str(coordinates)\n",
    "                df.loc[index, [\"center_of_mass_x\", \"center_of_mass_y\", \"center_of_mass_z\"]] = center_of_mass\n",
    "            else:\n",
    "                print(f\"Residue {residue_number} in chain {chain_id} not found in {pdb_file}.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {pdb_file} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# 4️⃣ Process and Update Data for a Single PDB Structure\n",
    "def process_and_update_pdb_data(data_path, pdb_code):\n",
    "    \"\"\"\n",
    "    Reads and processes a PDB file and corresponding CSV file to update residue information.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): Path to the directory containing the PDB and CSV files.\n",
    "        pdb_code (str): PDB code of the protein.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with residue information.\n",
    "    \"\"\"\n",
    "    csv_file_path = f\"{data_path}/results_{pdb_code}.csv\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        df_updated = process_pdb_file(data_path, pdb_code, df)\n",
    "        df_updated.to_csv(f\"{data_path}/results_{pdb_code}_updated.csv\", index=False)\n",
    "        return df_updated\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdb_code}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# 5️⃣ Process All PDB Files in a Directory\n",
    "def process_all_pdb_files(data_path):\n",
    "    \"\"\"\n",
    "    Process all PDB-related files in the given directory and combine results.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): Path to the directory containing the PDB and CSV files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame with all processed data.\n",
    "    \"\"\"\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    for file in os.listdir(data_path):\n",
    "        if file.startswith(\"results_\") and file.endswith(\".csv\"):\n",
    "            pdb_code = file.split(\"_\")[1].split(\".\")[0]\n",
    "            updated_df = process_and_update_pdb_data(data_path, pdb_code)\n",
    "            if updated_df is not None:\n",
    "                updated_df[\"PDBcode\"] = pdb_code\n",
    "                combined_df = pd.concat([combined_df, updated_df], ignore_index=True)\n",
    "\n",
    "    combined_df.drop_duplicates(inplace=True)\n",
    "    combined_df.to_csv(f\"{data_path}/combined_results.csv\", index=False)\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "# 6️⃣ Compute Center of Protein Using PyMOL\n",
    "def calculate_center_of_mass_pymol(pdb_file):\n",
    "    \"\"\"\n",
    "    Calculates the center of mass of a protein using PyMOL.\n",
    "\n",
    "    Args:\n",
    "        pdb_file (str): Path to the PDB file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (x, y, z) coordinates of the protein's center of mass.\n",
    "    \"\"\"\n",
    "    cmd.load(pdb_file, \"protein\")\n",
    "    center_of_mass = cmd.centerofmass(\"protein\")\n",
    "    cmd.delete(\"all\")\n",
    "    return round(center_of_mass[0], 3), round(center_of_mass[1], 3), round(center_of_mass[2], 3)\n",
    "\n",
    "\n",
    "# 7️⃣ Compute Protein Diameter\n",
    "def calculate_protein_diameter(df):\n",
    "    \"\"\"\n",
    "    Computes the diameter of a protein, defined as the maximum distance between residues.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing residue data with center of mass coordinates.\n",
    "\n",
    "    Returns:\n",
    "        float: Maximum distance between residues.\n",
    "    \"\"\"\n",
    "    coordinates = df[['center_of_mass_x', 'center_of_mass_y', 'center_of_mass_z']].values\n",
    "    distances = np.linalg.norm(coordinates[:, np.newaxis] - coordinates, axis=2)\n",
    "    return round(np.max(distances), 3)\n",
    "\n",
    "\n",
    "# 8️⃣ Process Protein Data for a Single PDB\n",
    "def process_protein_data(pdb_code, dfs, data_path):\n",
    "    \"\"\"\n",
    "    Processes protein data by computing center of mass and diameter.\n",
    "\n",
    "    Args:\n",
    "        pdb_code (str): The PDB code of the protein.\n",
    "        dfs (dict): Dictionary containing DataFrames indexed by PDB code.\n",
    "        data_path (str): Path to the directory containing the PDB files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with center of protein and diameter.\n",
    "    \"\"\"\n",
    "    pdb_file_path = f\"{data_path}/{pdb_code}.pdb\"\n",
    "    df = dfs[pdb_code]\n",
    "    center_of_mass = calculate_center_of_mass_pymol(pdb_file_path)\n",
    "    protein_diameter = calculate_protein_diameter(df)\n",
    "\n",
    "    df[\"protein_x\"], df[\"protein_y\"], df[\"protein_z\"] = center_of_mass\n",
    "    df[\"protein_diameter\"] = protein_diameter\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def normalize_features(df, feature_columns):\n",
    "    \"\"\"\n",
    "    Normalize or standardize features based on their distribution.\n",
    "\n",
    "    - **Standardizes (Z-score) if normally distributed**.\n",
    "    - **Normalizes (Min-Max) if not normally distributed**.\n",
    "    - **Adds new columns instead of replacing existing ones**.\n",
    "    - **Stores scalers for consistent transformation in clustering**.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing features.\n",
    "        feature_columns (list): List of feature column names (e.g., 3D coordinates).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added transformed feature columns.\n",
    "        dict: Dictionary of fitted scalers (for later reuse).\n",
    "    \"\"\"\n",
    "    processed_df = df.copy()\n",
    "    scalers = {}\n",
    "\n",
    "    for col in feature_columns:\n",
    "        scaler = MinMaxScaler()  # Normalization\n",
    "        new_col_name = f\"{col}_normalized\"\n",
    "\n",
    "        processed_df[new_col_name] = scaler.fit_transform(df[[col]])  # Apply transformation\n",
    "        scalers[col] = scaler  # Store scaler for reuse\n",
    "\n",
    "    return processed_df, scalers\n",
    "\n",
    "\n",
    "def weighted_pbind(df, pbind_column='p(bind)', weights=[1.0]):\n",
    "    \"\"\"\n",
    "    Normalize and apply multiple weight factors to p(bind).\n",
    "\n",
    "    - **Scales p(bind) between 0 and 1**.\n",
    "    - **Applies multiple weight factors** to create additional columns.\n",
    "    - **Adds new columns instead of replacing p(bind)**.\n",
    "    - **Stores scaler** for reuse in clustering.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing p(bind).\n",
    "        pbind_column (str): Column name for p(bind).\n",
    "        weights (list): List of weight multipliers (e.g., [1.0, 5.0, 10.0, 100.0]).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with weighted p(bind) columns.\n",
    "        dict: Dictionary of fitted scalers.\n",
    "    \"\"\"\n",
    "    processed_df = df.copy()\n",
    "    scalers = {}\n",
    "\n",
    "    if pbind_column in df.columns:\n",
    "        scaler = MinMaxScaler()\n",
    "        normalized_pbind = scaler.fit_transform(df[[pbind_column]])  # Scale to 0-1\n",
    "        scalers[pbind_column] = scaler  # Store scaler\n",
    "\n",
    "        for weight in weights:\n",
    "            weighted_col_name = f\"{pbind_column}_weight_{weight}\"\n",
    "            processed_df[weighted_col_name] = normalized_pbind * weight  # Apply weight\n",
    "\n",
    "    return processed_df, scalers\n",
    "    \"\"\"\n",
    "    Normalize and apply multiple weight factors to p(bind).\n",
    "\n",
    "    - **Scales p(bind) between 0 and 1**.\n",
    "    - **Applies multiple weight factors** to create additional columns.\n",
    "    - **Stores scaler** for reuse in clustering.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing p(bind).\n",
    "        pbind_column (str): Column name for p(bind).\n",
    "        weights (list): List of weight multipliers (e.g., [1.0, 1.5, 2.0]).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with weighted p(bind) columns.\n",
    "        dict: Dictionary of fitted scalers.\n",
    "    \"\"\"\n",
    "    processed_df = df.copy()\n",
    "    scalers = {}\n",
    "\n",
    "    if pbind_column in df.columns:\n",
    "        scaler = MinMaxScaler()\n",
    "        normalized_pbind = scaler.fit_transform(df[[pbind_column]])  # Scale to 0-1\n",
    "        scalers[pbind_column] = scaler  # Store scaler\n",
    "\n",
    "        for weight in weights:\n",
    "            weighted_col_name = f\"{pbind_column}_weight_{weight}\"\n",
    "            processed_df[weighted_col_name] = normalized_pbind * weight  # Apply weight\n",
    "\n",
    "    return processed_df, scalers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the clustering performance\n",
    "from numpy import size\n",
    "\n",
    "\n",
    "def calculate_protein_center_of_mass(pdb_file):\n",
    "    \"\"\"\n",
    "    Calculate the center of mass of the entire protein using PyMOL.\n",
    "\n",
    "    Args:\n",
    "        pdb_file (str): Path to the PDB file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Center of mass coordinates (x, y, z).\n",
    "    \"\"\"\n",
    "    cmd.load(pdb_file, \"protein\")\n",
    "    center_of_mass = cmd.centerofmass(\"protein\")\n",
    "    cmd.delete(\"all\")  # Clear the loaded structure\n",
    "    return tuple(round(coord, 3) for coord in center_of_mass)\n",
    "\n",
    "def calculate_cluster_centers(df, cluster_column, pdb_file):\n",
    "    \"\"\"\n",
    "    Calculate the center of mass for each cluster using PyMOL.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing residue and cluster information.\n",
    "        cluster_column (str): Column name containing cluster IDs.\n",
    "        pdb_file (str): Path to the PDB file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Cluster IDs as keys and their center of mass coordinates as values.\n",
    "    \"\"\"\n",
    "    cmd.load(pdb_file, \"protein\")\n",
    "    cluster_centers = {}\n",
    "    clusters = df[cluster_column].unique()\n",
    "\n",
    "    for cluster_id in clusters:\n",
    "        cluster_data = df[df[cluster_column] == cluster_id]\n",
    "        resi_selection = \"+\".join(map(str, cluster_data['resi']))\n",
    "        cmd.select(f\"cluster_{cluster_id}\", f\"resi {resi_selection}\")\n",
    "        center_of_mass = cmd.centerofmass(f\"cluster_{cluster_id}\")\n",
    "        cluster_centers[cluster_id] = tuple(round(coord, 3) for coord in center_of_mass)\n",
    "        cmd.delete(f\"cluster_{cluster_id}\")\n",
    "\n",
    "    cmd.delete(\"all\")  # Clear the loaded structure\n",
    "    return cluster_centers\n",
    "\n",
    "def calculate_ligand_centers_slow(pdb_file):\n",
    "    \"\"\"\n",
    "    Calculate the center of mass for each ligand in the structure using PyMOL.\n",
    "\n",
    "    Args:\n",
    "        pdb_file (str): Path to the PDB file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Ligand identifiers as keys and their center of mass coordinates as values.\n",
    "    \"\"\"\n",
    "    cmd.load(pdb_file, \"protein\")\n",
    "    cmd.select(\"ligands\", \"organic\")\n",
    "    ligand_centers = {}\n",
    "\n",
    "    for atom in cmd.get_model(\"ligands\").atom:\n",
    "        ligand_id = f\"{atom.chain}_{atom.resn}_{atom.resi}\"\n",
    "        cmd.select(\"ligand\", f\"chain {atom.chain} and resn {atom.resn} and resi {atom.resi}\")\n",
    "        center_of_mass = cmd.centerofmass(\"ligand\")\n",
    "        ligand_centers[ligand_id] = tuple(round(coord, 3) for coord in center_of_mass)\n",
    "        cmd.delete(\"ligand\")  # Clear the selection\n",
    "\n",
    "    cmd.delete(\"all\")  # Clear the loaded structure\n",
    "    return ligand_centers\n",
    "\n",
    "\n",
    "def calculate_ligand_centers(pdb_file):\n",
    "    \"\"\"\n",
    "    Calculate the center of mass for each ligand in the structure using PyMOL.\n",
    "\n",
    "    Args:\n",
    "        pdb_file (str): Path to the PDB file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Ligand identifiers as keys and their center of mass coordinates as values.\n",
    "    \"\"\"\n",
    "    cmd.load(pdb_file, \"protein\")\n",
    "    cmd.select(\"ligands\", \"organic\")\n",
    "    \n",
    "    ligand_centers = {}\n",
    "    stored.stored_atoms = []  # Corrected: Define `stored_atoms` in the PyMOL namespace\n",
    "\n",
    "    # Iterate through ligands and collect unique identifiers\n",
    "    cmd.iterate(\"ligands\", \"stored.stored_atoms.append((chain, resn, resi))\")\n",
    "\n",
    "    unique_ligands = set(stored.stored_atoms)  # Get unique ligand identifiers\n",
    "\n",
    "    for chain, resn, resi in unique_ligands:\n",
    "        ligand_id = f\"{chain}_{resn}_{resi}\"\n",
    "        cmd.select(\"ligand\", f\"chain {chain} and resn {resn} and resi {resi}\")\n",
    "        center_of_mass = cmd.centerofmass(\"ligand\")\n",
    "        ligand_centers[ligand_id] = tuple(round(coord, 3) for coord in center_of_mass)\n",
    "        cmd.delete(\"ligand\")  # Clear selection\n",
    "\n",
    "    cmd.delete(\"all\")  # Clear everything from PyMOL session\n",
    "    return ligand_centers\n",
    "\n",
    "def calculate_ligand_diameter(pdb_file):\n",
    "    \"\"\"\n",
    "    Calculate the diameter of each ligand (maximum pairwise distance between its atoms).\n",
    "\n",
    "    Args:\n",
    "        pdb_file (str): Path to the PDB file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Ligand identifiers as keys and their diameters as values.\n",
    "    \"\"\"\n",
    "    cmd.load(pdb_file, \"protein\")\n",
    "    cmd.select(\"ligands\", \"organic\")\n",
    "\n",
    "    ligand_diameters = {}\n",
    "\n",
    "    # Store ligand atom coordinates\n",
    "    stored.ligand_atoms = []\n",
    "    cmd.iterate_state(1, \"ligands\", \"stored.ligand_atoms.append((chain, resn, resi, x, y, z))\")\n",
    "\n",
    "    unique_ligands = {}\n",
    "    for chain, resn, resi, x, y, z in stored.ligand_atoms:\n",
    "        ligand_id = f\"{chain}_{resn}_{resi}\"\n",
    "        if ligand_id not in unique_ligands:\n",
    "            unique_ligands[ligand_id] = []\n",
    "        unique_ligands[ligand_id].append((x, y, z))\n",
    "\n",
    "    # Compute ligand diameters\n",
    "    for ligand_id, coordinates in unique_ligands.items():\n",
    "        if len(coordinates) > 1:\n",
    "            max_distance = max(\n",
    "                np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "                for p1, p2 in combinations(coordinates, 2)\n",
    "            )\n",
    "            ligand_diameters[ligand_id] = round(max_distance, 3)\n",
    "        else:\n",
    "            ligand_diameters[ligand_id] = 0.0  # Single atom ligand, diameter is zero\n",
    "\n",
    "    cmd.delete(\"all\")  # Clear the loaded structure\n",
    "    return ligand_diameters\n",
    "\n",
    "\n",
    "def calculate_grid_size_ligand(ligand_diameter):\n",
    "    \"\"\"\n",
    "    Compute the grid size based on the ligand diameter.\n",
    "\n",
    "    Args:\n",
    "        ligand_diameter (float): Diameter of the ligand.\n",
    "\n",
    "    Returns:\n",
    "        float: Computed grid size.\n",
    "    \"\"\"\n",
    "    return round(16 + (0.8 * ligand_diameter), 3)\n",
    "\n",
    "\n",
    "def define_bounding_box_ligand(ligand_centers, ligand_diameters):\n",
    "    \"\"\"\n",
    "    Define a bounding box around the ligands based on their diameters.\n",
    "\n",
    "    Args:\n",
    "        ligand_centers (dict): Ligand identifiers and their center of mass coordinates.\n",
    "        ligand_diameters (dict): Ligand identifiers and their diameters.\n",
    "\n",
    "    Returns:\n",
    "        dict: Bounding box coordinates for each ligand.\n",
    "    \"\"\"\n",
    "    bounding_boxes = {}\n",
    "\n",
    "    for ligand_id, center in ligand_centers.items():\n",
    "        if ligand_id not in ligand_diameters:\n",
    "            print(f\"Warning: Missing diameter for ligand {ligand_id}\")\n",
    "            continue\n",
    "\n",
    "        grid_size = calculate_grid_size_ligand(ligand_diameters[ligand_id])\n",
    "\n",
    "        min_coords = [center[i] - grid_size / 2 for i in range(3)]\n",
    "        max_coords = [center[i] + grid_size / 2 for i in range(3)]\n",
    "\n",
    "        bounding_boxes[ligand_id] = {\"min\": min_coords, \"max\": max_coords}\n",
    "\n",
    "        # Add pseudoatoms in PyMOL for visualization\n",
    "        cmd.pseudoatom(f\"box_{ligand_id}_min\", pos=min_coords, color=\"blue\")\n",
    "        cmd.pseudoatom(f\"box_{ligand_id}_max\", pos=max_coords, color=\"red\")\n",
    "\n",
    "        print(f\"Bounding box for {ligand_id}: Min={min_coords}, Max={max_coords}\")\n",
    "\n",
    "    return bounding_boxes\n",
    "\n",
    "def select_cluster_define_bounding_box(df, cluster_id, cluster_column, selection_name=\"cluster_selection\"):\n",
    "    \"\"\"\n",
    "    Select residues based on the clustering method and create a bounding box in PyMOL.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing residue data.\n",
    "        cluster_id (int): The cluster ID to select residues for.\n",
    "        cluster_column (str): Column name that stores cluster assignments.\n",
    "        selection_name (str): Name of the selection in PyMOL.\n",
    "\n",
    "    Returns:\n",
    "        dict: Bounding box coordinates { \"min\": np.array, \"max\": np.array } for the selected cluster.\n",
    "    \"\"\"\n",
    "    # Ensure required columns exist\n",
    "    required_columns = {\"chain\", \"resi\", \"center_of_mass_x\", \"center_of_mass_y\", \"center_of_mass_z\"}\n",
    "    missing_columns = required_columns - set(df.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing columns in DataFrame: {missing_columns}\")\n",
    "\n",
    "    # Filter residues based on the selected cluster\n",
    "    selected_residues = df[df[cluster_column] == cluster_id]\n",
    "    \n",
    "    if selected_residues.empty:\n",
    "        print(f\"⚠️ No residues found for cluster {cluster_id} in column '{cluster_column}'\")\n",
    "        return None\n",
    "\n",
    "    # Construct a PyMOL selection string\n",
    "    selection_string = \" or \".join(\n",
    "        [f\"(chain {row['chain']} and resi {row['resi']})\" for _, row in selected_residues.iterrows()]\n",
    "    )\n",
    "\n",
    "    # Check if PyMOL is available\n",
    "    try:\n",
    "        cmd.select(selection_name, selection_string)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ PyMOL selection failed: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Compute the bounding box\n",
    "    min_coords = selected_residues[['center_of_mass_x', 'center_of_mass_y', 'center_of_mass_z']].min().to_numpy()\n",
    "    max_coords = selected_residues[['center_of_mass_x', 'center_of_mass_y', 'center_of_mass_z']].max().to_numpy()\n",
    "\n",
    "    # Convert coordinates to float for compatibility\n",
    "    min_coords = np.array([float(coord) for coord in min_coords])\n",
    "    max_coords = np.array([float(coord) for coord in max_coords])\n",
    "\n",
    "    # Add pseudoatoms for visualization\n",
    "    try:\n",
    "        cmd.pseudoatom(f\"{selection_name}_box_min\", pos=min_coords.tolist(), color=\"blue\")\n",
    "        cmd.pseudoatom(f\"{selection_name}_box_max\", pos=max_coords.tolist(), color=\"red\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to create pseudoatoms in PyMOL: {e}\")\n",
    "\n",
    "    print(f\"✅ Selection '{selection_name}' created for cluster {cluster_id}\")\n",
    "    print(f\"📦 Bounding box: Min={min_coords.tolist()}, Max={max_coords.tolist()}\")\n",
    "    \n",
    "    #euclidean distance\n",
    "    size = np.linalg.norm(max_coords - min_coords)\n",
    "\n",
    "    return {\"min\": min_coords, \"max\": max_coords, \"size\": size}\n",
    "\n",
    "\n",
    "def calculate_dice_score(cluster_selection, ligand_selection):\n",
    "    \"\"\"\n",
    "    Compute the Dice similarity coefficient between a cluster and a ligand.\n",
    "\n",
    "    Args:\n",
    "        cluster_selection (str): PyMOL selection name for the cluster.\n",
    "        ligand_selection (str): PyMOL selection name for the ligand.\n",
    "\n",
    "    Returns:\n",
    "        float: Dice score indicating spatial overlap (higher means better overlap).\n",
    "    \"\"\"\n",
    "    # Get atoms in selections\n",
    "    cluster_atoms = set(cmd.index(cluster_selection))\n",
    "    ligand_atoms = set(cmd.index(ligand_selection))\n",
    "\n",
    "    if not cluster_atoms or not ligand_atoms:\n",
    "        print(f\"Error: One or both selections are empty: {cluster_selection}, {ligand_selection}\")\n",
    "        return 0.0\n",
    "\n",
    "    # Compute Dice coefficient\n",
    "    intersection = len(cluster_atoms & ligand_atoms)\n",
    "    dice_score = (2 * intersection) / (len(cluster_atoms) + len(ligand_atoms))\n",
    "\n",
    "    print(f\"Dice Score between {cluster_selection} and {ligand_selection}: {round(dice_score, 3)}\")\n",
    "    \n",
    "    return round(dice_score, 3)\n",
    "\n",
    "def calculate_distances_between_clusters_and_ligands(cluster_centers, ligand_centers):\n",
    "    \"\"\"\n",
    "    Calculate the minimum distance between each cluster and the ligands.\n",
    "\n",
    "    Args:\n",
    "        cluster_centers (dict): Cluster IDs and their center of mass coordinates.\n",
    "        ligand_centers (dict): Ligand identifiers and their center of mass coordinates.\n",
    "\n",
    "    Returns:\n",
    "        dict: Cluster IDs as keys and tuples of (closest ligand ID, distance) as values.\n",
    "    \"\"\"\n",
    "    distances = {}\n",
    "\n",
    "    for cluster_id, cluster_center in cluster_centers.items():\n",
    "        min_distance = float('inf')\n",
    "        closest_ligand = None\n",
    "\n",
    "        for ligand_id, ligand_center in ligand_centers.items():\n",
    "            distance = np.linalg.norm(np.array(cluster_center) - np.array(ligand_center))\n",
    "            if distance < min_distance:\n",
    "                min_distance = round(distance, 3)\n",
    "                closest_ligand = ligand_id\n",
    "\n",
    "        distances[cluster_id] = (closest_ligand, min_distance)\n",
    "\n",
    "    return distances\n",
    "\n",
    "def evaluate_clustering(pdb_file, df, cluster_column):\n",
    "    \"\"\"\n",
    "    Evaluate the clustering by calculating distances between cluster centers and ligand centers.\n",
    "\n",
    "    Args:\n",
    "        pdb_file (str): Path to the PDB file.\n",
    "        df (pd.DataFrame): DataFrame containing residue and cluster information.\n",
    "        cluster_column (str): Column name containing cluster IDs.\n",
    "\n",
    "    Returns:\n",
    "        dict: Distances between each cluster and the closest ligand.\n",
    "    \"\"\"\n",
    "    print(\"Calculating cluster centers...\")\n",
    "    cluster_centers = calculate_cluster_centers(df, cluster_column, pdb_file)\n",
    "\n",
    "    print(\"Calculating ligand centers...\")\n",
    "    ligand_centers = calculate_ligand_centers(pdb_file)\n",
    "\n",
    "    print(\"Calculating distances between clusters and ligands...\")\n",
    "    distances = calculate_distances_between_clusters_and_ligands(cluster_centers, ligand_centers)\n",
    "\n",
    "    for cluster_id, (ligand_id, distance) in distances.items():\n",
    "        print(f\"Cluster {cluster_id} -> Closest Ligand: {ligand_id}, Distance: {distance} Å\")\n",
    "\n",
    "    return distances\n",
    "\n",
    "# Pipeline Function\n",
    "def run_pipeline(data_path, pdb_file, clustering_method, cluster_params, pbind_column='p(bind)', cutoff_method='median_std', std_factor=0.5):\n",
    "    \"\"\"\n",
    "    Run the clustering pipeline, including clustering, normalization, filtering, and evaluation.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): Path to the data directory.\n",
    "        pdb_file (str): Path to the PDB file.\n",
    "        clustering_method (str): Clustering method to use ('kmeans' or 'spectral').\n",
    "        cluster_params (dict): Parameters for the clustering method.\n",
    "        pbind_column (str): Column name for binding probabilities.\n",
    "        cutoff_method (str): Method for calculating cutoff ('median_std' or 'percentile').\n",
    "        std_factor (float): Factor for standard deviation when calculating cutoff.\n",
    "\n",
    "    Returns:\n",
    "        dict: Evaluation results including distances between clusters and ligands.\n",
    "    \"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    combined_df = process_all_pdb_files(data_path)\n",
    "\n",
    "    print(\"Applying clustering...\")\n",
    "    if clustering_method == 'kmeans':\n",
    "        n_clusters = cluster_params.get('n_clusters', 3)\n",
    "        combined_df, _ = kmeans_clustering(combined_df, feature_columns=cluster_params['feature_columns'], n_clusters=n_clusters)\n",
    "    elif clustering_method == 'spectral':\n",
    "        n_clusters = cluster_params.get('n_clusters', 3)\n",
    "        affinity = cluster_params.get('affinity', 'nearest_neighbors')\n",
    "        combined_df, _ = spectral_clustering(combined_df, feature_columns=cluster_params['feature_columns'], n_clusters=n_clusters, affinity=affinity)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid clustering method. Choose 'kmeans' or 'spectral'.\")\n",
    "\n",
    "    print(\"Normalizing p(bind) within clusters...\")\n",
    "    combined_df = normalize_within_clusters(combined_df, cluster_column=clustering_method+'_cluster', pbind_column=pbind_column)\n",
    "\n",
    "    print(\"Filtering residues based on p(bind) cutoff...\")\n",
    "    filtered_df = filter_by_pbind_cutoff(combined_df, pbind_column=pbind_column, cluster_column=clustering_method+'_cluster', cutoff_method=cutoff_method, std_factor=std_factor)\n",
    "\n",
    "    print(\"Evaluating clustering...\")\n",
    "    evaluation_results = evaluate_clustering(pdb_file, filtered_df, cluster_column=clustering_method+'_cluster')\n",
    "\n",
    "    return {\n",
    "        'clustered_df': combined_df,\n",
    "        'filtered_df': filtered_df,\n",
    "        'evaluation_results': evaluation_results\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1qcf: ✅ Match - 450 entries\n",
      "1ubq: ✅ Match - 76 entries\n",
      "3g5d: ✅ Match - 513 entries\n",
      "3zln: ✅ Match - 144 entries\n",
      "4f9w: ✅ Match - 336 entries\n",
      "1lyz: ✅ Match - 129 entries\n",
      "1hvy: ✅ Match - 1152 entries\n",
      "3hvc: ✅ Match - 327 entries\n",
      "3cpa: ✅ Match - 307 entries\n",
      "1pw6: ✅ Match - 250 entries\n",
      "1ema: ✅ Match - 225 entries\n",
      "1kv1: ✅ Match - 331 entries\n",
      "1be9: ✅ Match - 120 entries\n",
      "3ptb: ✅ Match - 220 entries\n",
      "6o0k: ✅ Match - 141 entries\n",
      "2bal: ✅ Match - 338 entries\n",
      "4pti: ✅ Match - 58 entries\n",
      "1yer: ✅ Match - 207 entries\n",
      "1cz2: ✅ Match - 90 entries\n",
      "3qkd: ✅ Match - 282 entries\n",
      "1ao6: ✅ Match - 1156 entries\n",
      "1h61: ✅ Match - 364 entries\n",
      "1ny3: ✅ Match - 277 entries\n",
      " Warning: 'protein' may become a reserved selection keyword in the future\n",
      "\n",
      "✅ Processed Data Example:\n",
      "     chain  resi resn   p(bind)  \\\n",
      "8133     A     5    S  0.008225   \n",
      "8134     A     6    E  0.013932   \n",
      "8135     A     7    V  0.044013   \n",
      "8136     A     8    A  0.005330   \n",
      "8137     A     9    H  0.007117   \n",
      "\n",
      "                                       resn_coordinates  center_of_mass_x  \\\n",
      "8133  [('N', 56.653, 51.017, 34.141), ('C', 56.672, ...            56.842   \n",
      "8134  [('N', 54.513, 49.256, 32.336), ('C', 53.399, ...            52.042   \n",
      "8135  [('N', 54.398, 47.06, 30.567), ('C', 54.785, 4...            55.496   \n",
      "8136  [('N', 56.576, 45.684, 31.451), ('C', 57.619, ...            57.393   \n",
      "8137  [('N', 55.959, 45.021, 34.015), ('C', 55.239, ...            53.670   \n",
      "\n",
      "      center_of_mass_y  center_of_mass_z PDBcode  center_of_mass_x_normalized  \\\n",
      "8133            49.491            33.021    1ao6                     0.878999   \n",
      "8134            47.843            32.726    1ao6                     0.818612   \n",
      "8135            45.623            29.468    1ao6                     0.862065   \n",
      "8136            44.835            32.769    1ao6                     0.885931   \n",
      "8137            44.278            36.142    1ao6                     0.839093   \n",
      "\n",
      "      ...  p(bind)_weight_2  p(bind)_weight_5  p(bind)_weight_10  \\\n",
      "8133  ...          0.015545          0.038863           0.077726   \n",
      "8134  ...          0.027592          0.068981           0.137962   \n",
      "8135  ...          0.091084          0.227710           0.455420   \n",
      "8136  ...          0.009434          0.023586           0.047172   \n",
      "8137  ...          0.013208          0.033020           0.066040   \n",
      "\n",
      "      p(bind)_weight_20  p(bind)_weight_50  p(bind)_weight_100  protein_x  \\\n",
      "8133           0.155452           0.388629            0.777258     28.415   \n",
      "8134           0.275924           0.689810            1.379621     28.415   \n",
      "8135           0.910840           2.277101            4.554202     28.415   \n",
      "8136           0.094343           0.235859            0.471717     28.415   \n",
      "8137           0.132079           0.330198            0.660397     28.415   \n",
      "\n",
      "      protein_y  protein_z  protein_diameter  \n",
      "8133      8.385      23.27           115.953  \n",
      "8134      8.385      23.27           115.953  \n",
      "8135      8.385      23.27           115.953  \n",
      "8136      8.385      23.27           115.953  \n",
      "8137      8.385      23.27           115.953  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Execute the data processing pipeline\n",
    "\n",
    "# Process all files and get the combined DataFrame\n",
    "combined_df = process_all_pdb_files(data_path)\n",
    "\n",
    "# Ensure 'PDBcode' is present in combined_df\n",
    "if 'PDBcode' not in combined_df.columns:\n",
    "    raise ValueError(\"Error: 'PDBcode' column is missing in combined_df. Check preprocessing.\")\n",
    "\n",
    "# Create a dictionary of dataframes grouped by PDBcode\n",
    "dfs = {pdb: df for pdb, df in combined_df.groupby('PDBcode')}\n",
    "\n",
    "# Check if extracted dataframes match the original CSV files\n",
    "for pdb in combined_df['PDBcode'].unique():\n",
    "    original_csv_path = os.path.join(data_path, f\"results_{pdb}.csv\")\n",
    "    \n",
    "    if not os.path.exists(original_csv_path):\n",
    "        print(f\"Warning: Original CSV file missing for {pdb}. Skipping...\")\n",
    "        continue\n",
    "    \n",
    "    original_df = pd.read_csv(original_csv_path)\n",
    "    \n",
    "    if pdb in dfs:\n",
    "        extracted_df = dfs[pdb]\n",
    "    else:\n",
    "        print(f\"Warning: {pdb} missing in processed data. Reprocessing...\")\n",
    "        extracted_df = process_and_update_pdb_data(data_path, pdb)\n",
    "\n",
    "    # Check if the number of entries match\n",
    "    if len(original_df) == len(extracted_df):\n",
    "        print(f\"{pdb}: ✅ Match - {len(original_df)} entries\")\n",
    "    else:\n",
    "        print(f\"{pdb}: ❌ Mismatch - Original: {len(original_df)} entries, Extracted: {len(extracted_df)} entries\")\n",
    "        \n",
    "        # Attempt to fix by loading updated version\n",
    "        updated_csv_path = os.path.join(data_path, f\"results_{pdb}_updated.csv\")\n",
    "        \n",
    "        if os.path.exists(updated_csv_path):\n",
    "            print(f\"Fixing process by using updated data for {pdb}...\")\n",
    "            extracted_df = pd.read_csv(updated_csv_path)\n",
    "            dfs[pdb] = extracted_df  # Update dictionary\n",
    "            \n",
    "            if len(original_df) == len(extracted_df):\n",
    "                print(f\"{pdb}: ✅ Fixed - Match after update: {len(original_df)} entries\")\n",
    "            else:\n",
    "                print(f\"{pdb}: ❌ Still Mismatch after update: {len(original_df)} vs {len(extracted_df)} entries\")\n",
    "        else:\n",
    "            print(f\"Error: No updated file found for {pdb}. Manual check required.\")\n",
    "\n",
    "# Define feature and p(bind) column\n",
    "feature_columns = ['center_of_mass_x', 'center_of_mass_y', 'center_of_mass_z']\n",
    "pbind_column = 'p(bind)'\n",
    "\n",
    "# Process features for each PDB entry\n",
    "for pdb_code in dfs.keys():\n",
    "    # Normalize spatial features\n",
    "    dfs[pdb_code], feature_scalers = normalize_features(dfs[pdb_code], feature_columns)\n",
    "    \n",
    "    # Apply multiple p(bind) weight factors\n",
    "    dfs[pdb_code], pbind_scalers = weighted_pbind(dfs[pdb_code], pbind_column, weights=[1, 2, 5, 10, 20, 50, 100])\n",
    "\n",
    "    # Process protein metadata (diameter, center of mass)\n",
    "    dfs[pdb_code] = process_protein_data(pdb_code, dfs, data_path)\n",
    "\n",
    "    # Rename and clean up dataframe\n",
    "    dfs[pdb_code].rename(columns=lambda x: x.strip(), inplace=True)\n",
    "    dfs[pdb_code].drop(columns=\"Unnamed: 0\", inplace=True, errors=\"ignore\")  # Avoid errors if column missing\n",
    "\n",
    "# Print an example output for verification\n",
    "print(\"\\n✅ Processed Data Example:\")\n",
    "print(dfs[list(dfs.keys())[0]].head())  # Print first PDB's processed dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested number of clusters (Silhouette): 2\n",
      "Silhouette Scores: [0.6355500000273376, 0.5408567437236194, 0.47825751533187444, 0.5465603793327393, 0.5558734824532885, 0.4738380218244981, 0.3953970140689803, 0.30661873196590006, 0.2537951909943017]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v4/rd2_123918b6cj4v96gtlmkh0000gn/T/ipykernel_62066/3448447106.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['kmeans_cluster'] = kmeans.fit_predict(features)\n",
      "/var/folders/v4/rd2_123918b6cj4v96gtlmkh0000gn/T/ipykernel_62066/3448447106.py:135: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_kmeans['residue_id'] = df_kmeans['chain'] + '_' + df_kmeans['resi'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Median clustering function\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def silhouette_analysis(data, max_clusters=10):\n",
    "    \"\"\"\n",
    "    Perform silhouette analysis for a range of clusters and suggest the optimal n_clusters.\n",
    "\n",
    "    Args:\n",
    "        data (array-like): Dataset to cluster.\n",
    "        max_clusters (int): Maximum number of clusters to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Suggested n_clusters, silhouette scores for each k.\n",
    "    \"\"\"\n",
    "    silhouette_scores = []\n",
    "    \n",
    "    for n_clusters in range(2, max_clusters + 1):  # Silhouette starts from k=2\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        labels = kmeans.fit_predict(data)\n",
    "        silhouette_scores.append(silhouette_score(data, labels))\n",
    "\n",
    "    suggested_k = np.argmax(silhouette_scores) + 2  # +2 because we start at k=2\n",
    "    print(f\"Suggested number of clusters (Silhouette): {suggested_k}\")\n",
    "    print(\"Silhouette Scores:\", silhouette_scores)\n",
    "    \n",
    "    return suggested_k, silhouette_scores\n",
    "\n",
    "\n",
    "def kmeans_clustering(df, feature_columns, n_clusters):\n",
    "    \"\"\"\n",
    "    Perform KMeans clustering and add cluster labels to the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        feature_columns (list): List of feature column names.\n",
    "        n_clusters (int): Number of clusters.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with cluster labels.\n",
    "        KMeans: Fitted KMeans model.\n",
    "    \"\"\"\n",
    "    features = df[feature_columns].values\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    df['kmeans_cluster'] = kmeans.fit_predict(features)\n",
    "    return df, kmeans\n",
    "\n",
    "\n",
    "def normalize_within_clusters(df, cluster_column, pbind_column):\n",
    "    \"\"\"\n",
    "    Normalize p(bind) values within each cluster.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        cluster_column (str): Column containing cluster IDs.\n",
    "        pbind_column (str): Column containing p(bind) values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with normalized p(bind) values.\n",
    "    \"\"\"\n",
    "    df[f\"normalized_{pbind_column}\"] = df.groupby(cluster_column)[pbind_column].transform(\n",
    "        lambda x: (x - x.min()) / (x.max() - x.min())\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_by_pbind_cutoff(df, pbind_column, cluster_column, cutoff_method, std_factor):\n",
    "    \"\"\"\n",
    "    Filter residues based on p(bind) cutoff.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        pbind_column (str): Column containing p(bind) values.\n",
    "        cluster_column (str): Column containing cluster IDs.\n",
    "        cutoff_method (str): Method for calculating cutoff ('median_std' or 'percentile').\n",
    "        std_factor (float): Factor for standard deviation in cutoff calculation.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame.\n",
    "    \"\"\"\n",
    "    filtered_df = pd.DataFrame()\n",
    "\n",
    "    for cluster_id in df[cluster_column].unique():\n",
    "        cluster_data = df[df[cluster_column] == cluster_id]\n",
    "        if cutoff_method == 'median_std':\n",
    "            median_value = cluster_data[pbind_column].median()\n",
    "            std_value = cluster_data[pbind_column].std()\n",
    "            cutoff = median_value + std_factor * std_value\n",
    "        elif cutoff_method == 'percentile':\n",
    "            cutoff = cluster_data[pbind_column].quantile(0.95)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid cutoff method. Use 'median_std' or 'percentile'.\")\n",
    "\n",
    "        filtered_cluster = cluster_data[cluster_data[pbind_column] > cutoff]\n",
    "        filtered_df = pd.concat([filtered_df, filtered_cluster])\n",
    "\n",
    "    return filtered_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def compute_centroids(df, cluster_column):\n",
    "                # Compute the cluster centers and round to 3 decimal places\n",
    "                centroids = df.groupby(cluster_column)[['p(bind)', 'center_of_mass_x', 'center_of_mass_y', 'center_of_mass_z']].mean().round(3)\n",
    "                centroids.sort_values(by='p(bind)')\n",
    "                \n",
    "                return centroids\n",
    "\n",
    "\n",
    "def med_clustering(df, std_factors, feature_columns, pbind_column, pbind_weight):\n",
    "    \"\"\" Perform clustering to identify residues with high binding probabilities. \"\"\"\n",
    "\n",
    "    \n",
    "    # 🔹 Step 1:Compute median and std for filtering\n",
    "    median_value = df[pbind_column].median()\n",
    "    std_value = df[pbind_column].std()\n",
    "    \n",
    "    cutoff = median_value + std_factors * std_value\n",
    "    df_filtered = df.loc[df[pbind_column] > cutoff]\n",
    "            \n",
    "    feature_columns = feature_columns + [pbind_column]*pbind_weight\n",
    "    \n",
    "    # 🔹 Step 2: Determine optimal number of clusters safely\n",
    "    optimal_kmeans, _ = silhouette_analysis(df_filtered[feature_columns].values, max_clusters=min(10, len(df_filtered) - 1))\n",
    "    \n",
    "    # 🔹 Step 3: Run Clustering with Optimal Clusters\n",
    "    df_kmeans, _ = kmeans_clustering(df_filtered, feature_columns, n_clusters=optimal_kmeans)\n",
    "    \n",
    "    # Store cluster labels\n",
    "    #df_filtered[f'kmeans_pbind'] = df_kmeans['kmeans_cluster']\n",
    "    \n",
    "    # 🔹 Step 4: Compute Cluster Center\n",
    "    centroids = compute_centroids(df_kmeans, 'kmeans_cluster')\n",
    "    \n",
    "    # Compute residue IDs for each cluster: pls \n",
    "    df_kmeans['residue_id'] = df_kmeans['chain'] + '_' + df_kmeans['resi'].astype(str)\n",
    "    centroids[\"residue_ids\"] = df_kmeans.groupby('kmeans_cluster')['residue_id'].apply(list)\n",
    "    \n",
    "    # make in this format w/o , and []: A_105 A_106 A_107\n",
    "    centroids[\"residue_ids\"] = centroids[\"residue_ids\"].apply(lambda x: ' '.join(x))\n",
    "    \n",
    "    # Rename columns\n",
    "    centroids['rank'] = centroids['p(bind)'].rank(ascending=False).astype(int)\n",
    "    centroids['name'] = \"pocket\" + centroids['rank'].astype(str)\n",
    "    centroids['name'] = centroids['name'].apply(lambda x: re.sub(r'\\.0', '', x))\n",
    "    \n",
    "    # 🔹 Rename columns\n",
    "    centroids['rank'] = centroids['p(bind)'].rank(ascending=False, method='dense').astype(int)\n",
    "    centroids['name'] = \"pocket\" + centroids['rank'].astype(str)\n",
    "    centroids['name'] = centroids['name'].apply(lambda x: re.sub(r'\\.0', '', x))\n",
    "        \n",
    "    # Select and rename columns\n",
    "    centroids = centroids[['name', 'rank', 'p(bind)', 'center_of_mass_x', 'center_of_mass_y', 'center_of_mass_z', 'residue_ids']]\n",
    "    centroids.rename(columns={'p(bind)': 'probability', 'center_of_mass_x': 'center_x', 'center_of_mass_y': 'center_y', 'center_of_mass_z': 'center_z'}, inplace=True)\n",
    "        \n",
    "    # Sort by binding probability\n",
    "    centroids.sort_values(by='probability', ascending=False, inplace=True)\n",
    "        \n",
    "    # Save to CSV\n",
    "    centroids.to_csv(\"pockets.csv\", index=False)\n",
    "\n",
    "    # 🔹 Prepare the residues DataFrame\n",
    "    residues_df = df[['chain', 'resi','resn', 'p(bind)', 'center_of_mass_x', 'center_of_mass_y', 'center_of_mass_z']].copy()\n",
    "    residues_df['pocket'] = np.nan  # Initialize pocket column\n",
    "        \n",
    "    # Assign pocket values based on clustering results\n",
    "    cluster_mapping = dict(zip(df_kmeans['residue_id'], df_kmeans['kmeans_cluster'] + 1))  # Map cluster IDs to pockets (1-based index)\n",
    "    residues_df['residue_id'] = residues_df['chain'] + '_' + residues_df['resi'].astype(str)\n",
    "    residues_df['pocket'] = residues_df['residue_id'].map(cluster_mapping).fillna(0).astype(int)  # NA means no cluster -> assign 0\n",
    "        \n",
    "    # Save final results\n",
    "    residues_df.to_csv(\"residues.csv\", index=False)\n",
    "\n",
    "    return residues_df, centroids \n",
    "\n",
    "df = dfs['3hvc']\n",
    "pdb_file =f\"{data_path}/3hvc.pdb\"\n",
    "ligand_center = calculate_ligand_centers(pdb_file)\n",
    "feature_columns = ['center_of_mass_x_normalized', 'center_of_mass_y_normalized', 'center_of_mass_z_normalized']\n",
    "pbind_column = 'p(bind)_weight_1'\n",
    "\n",
    "\n",
    "df_kmean, centroid = med_clustering(df, 2.5, feature_columns, pbind_column, 100)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pocket\n",
       "0    311\n",
       "2      9\n",
       "1      7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kmean.pocket.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "kmeans_cluster",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rank",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "probability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "center_x",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "center_y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "center_z",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "residue_ids",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "048a6e46-ed45-4460-9a7f-752d61ba3c53",
       "rows": [
        [
         "1",
         "pocket1",
         "1",
         "0.84",
         "-3.75",
         "35.536",
         "20.913",
         "A_36 A_38 A_51 A_53 A_71 A_84 A_106 A_167 A_168"
        ],
        [
         "0",
         "pocket2",
         "2",
         "0.577",
         "0.726",
         "32.606",
         "20.853",
         "A_31 A_67 A_104 A_109 A_149 A_150 A_155"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "      <th>probability</th>\n",
       "      <th>center_x</th>\n",
       "      <th>center_y</th>\n",
       "      <th>center_z</th>\n",
       "      <th>residue_ids</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmeans_cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pocket1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.840</td>\n",
       "      <td>-3.750</td>\n",
       "      <td>35.536</td>\n",
       "      <td>20.913</td>\n",
       "      <td>A_36 A_38 A_51 A_53 A_71 A_84 A_106 A_167 A_168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pocket2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.726</td>\n",
       "      <td>32.606</td>\n",
       "      <td>20.853</td>\n",
       "      <td>A_31 A_67 A_104 A_109 A_149 A_150 A_155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  rank  probability  center_x  center_y  center_z  \\\n",
       "kmeans_cluster                                                             \n",
       "1               pocket1     1        0.840    -3.750    35.536    20.913   \n",
       "0               pocket2     2        0.577     0.726    32.606    20.853   \n",
       "\n",
       "                                                    residue_ids  \n",
       "kmeans_cluster                                                   \n",
       "1               A_36 A_38 A_51 A_53 A_71 A_84 A_106 A_167 A_168  \n",
       "0                       A_31 A_67 A_104 A_109 A_149 A_150 A_155  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "chain",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "resi",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "resn",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "p(bind)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "center_of_mass_x",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "center_of_mass_y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "center_of_mass_z",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pocket",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "residue_id",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6ac2e36e-ab2b-40a7-9b77-781f3b979540",
       "rows": [
        [
         "2800",
         "A",
         "5",
         "R",
         "0.039529245",
         "-24.874",
         "37.998",
         "29.439",
         "0",
         "A_5"
        ],
        [
         "2801",
         "A",
         "6",
         "P",
         "0.034047898",
         "-23.549",
         "40.555",
         "27.539",
         "0",
         "A_6"
        ],
        [
         "2802",
         "A",
         "7",
         "T",
         "0.0035355922",
         "-26.034",
         "40.724",
         "23.731",
         "0",
         "A_7"
        ],
        [
         "2803",
         "A",
         "8",
         "F",
         "0.0060059493",
         "-23.113",
         "37.045",
         "23.328",
         "0",
         "A_8"
        ],
        [
         "2804",
         "A",
         "9",
         "Y",
         "0.0016957241",
         "-22.688",
         "38.464",
         "17.061",
         "0",
         "A_9"
        ],
        [
         "2805",
         "A",
         "10",
         "R",
         "0.00059366686",
         "-24.025",
         "31.304",
         "16.256",
         "0",
         "A_10"
        ],
        [
         "2806",
         "A",
         "11",
         "Q",
         "0.0013087553",
         "-20.528",
         "34.603",
         "13.067",
         "0",
         "A_11"
        ],
        [
         "2807",
         "A",
         "12",
         "E",
         "0.00073863164",
         "-19.911",
         "29.518",
         "10.198",
         "0",
         "A_12"
        ],
        [
         "2808",
         "A",
         "13",
         "L",
         "0.0032519058",
         "-16.129",
         "32.4",
         "10.427",
         "0",
         "A_13"
        ],
        [
         "2809",
         "A",
         "14",
         "N",
         "0.022676304",
         "-13.359",
         "29.519",
         "8.141",
         "0",
         "A_14"
        ],
        [
         "2810",
         "A",
         "15",
         "K",
         "0.0076594716",
         "-15.609",
         "24.677",
         "8.618",
         "0",
         "A_15"
        ],
        [
         "2811",
         "A",
         "16",
         "T",
         "0.017679509",
         "-15.361",
         "28.27",
         "13.063",
         "0",
         "A_16"
        ],
        [
         "2812",
         "A",
         "17",
         "I",
         "0.0011228818",
         "-19.02",
         "28.658",
         "15.492",
         "0",
         "A_17"
        ],
        [
         "2813",
         "A",
         "18",
         "W",
         "0.016597053",
         "-15.832",
         "32.995",
         "15.997",
         "0",
         "A_18"
        ],
        [
         "2814",
         "A",
         "19",
         "E",
         "0.002587375",
         "-21.037",
         "32.215",
         "20.265",
         "0",
         "A_19"
        ],
        [
         "2815",
         "A",
         "20",
         "V",
         "0.006985143",
         "-19.342",
         "37.466",
         "20.04",
         "0",
         "A_20"
        ],
        [
         "2816",
         "A",
         "21",
         "P",
         "0.0070247455",
         "-19.974",
         "40.13",
         "22.321",
         "0",
         "A_21"
        ],
        [
         "2817",
         "A",
         "22",
         "E",
         "0.0010002918",
         "-23.862",
         "43.381",
         "20.409",
         "0",
         "A_22"
        ],
        [
         "2818",
         "A",
         "23",
         "R",
         "0.0072041894",
         "-17.737",
         "45.257",
         "22.792",
         "0",
         "A_23"
        ],
        [
         "2819",
         "A",
         "24",
         "Y",
         "0.01384173",
         "-16.317",
         "42.737",
         "20.551",
         "0",
         "A_24"
        ],
        [
         "2820",
         "A",
         "25",
         "Q",
         "0.0018480881",
         "-19.296",
         "44.127",
         "15.04",
         "0",
         "A_25"
        ],
        [
         "2821",
         "A",
         "26",
         "N",
         "0.00634375",
         "-15.915",
         "43.533",
         "10.848",
         "0",
         "A_26"
        ],
        [
         "2822",
         "A",
         "27",
         "L",
         "0.012526404",
         "-15.58",
         "39.286",
         "13.022",
         "0",
         "A_27"
        ],
        [
         "2823",
         "A",
         "28",
         "S",
         "0.048782405",
         "-11.917",
         "39.147",
         "10.098",
         "0",
         "A_28"
        ],
        [
         "2824",
         "A",
         "29",
         "P",
         "0.053905353",
         "-10.484",
         "35.946",
         "9.326",
         "0",
         "A_29"
        ],
        [
         "2825",
         "A",
         "30",
         "V",
         "0.34186763",
         "-5.915",
         "36.685",
         "10.807",
         "0",
         "A_30"
        ],
        [
         "2826",
         "A",
         "31",
         "G",
         "0.5572299",
         "-5.722",
         "33.118",
         "11.88",
         "1",
         "A_31"
        ],
        [
         "2827",
         "A",
         "32",
         "S",
         "0.20038687",
         "-4.304",
         "30.404",
         "13.602",
         "0",
         "A_32"
        ],
        [
         "2828",
         "A",
         "36",
         "G",
         "0.76669675",
         "-6.642",
         "28.671",
         "17.527",
         "2",
         "A_36"
        ],
        [
         "2829",
         "A",
         "37",
         "S",
         "0.10781854",
         "-9.011",
         "30.835",
         "15.838",
         "0",
         "A_37"
        ],
        [
         "2830",
         "A",
         "38",
         "V",
         "0.88128424",
         "-7.559",
         "34.871",
         "15.162",
         "2",
         "A_38"
        ],
        [
         "2831",
         "A",
         "39",
         "C",
         "0.047566254",
         "-11.024",
         "37.022",
         "14.171",
         "0",
         "A_39"
        ],
        [
         "2832",
         "A",
         "40",
         "A",
         "0.20422311",
         "-10.403",
         "40.759",
         "13.184",
         "0",
         "A_40"
        ],
        [
         "2833",
         "A",
         "41",
         "A",
         "0.041072745",
         "-12.19",
         "43.399",
         "15.153",
         "0",
         "A_41"
        ],
        [
         "2834",
         "A",
         "42",
         "F",
         "0.0077128354",
         "-14.505",
         "48.163",
         "15.779",
         "0",
         "A_42"
        ],
        [
         "2835",
         "A",
         "43",
         "D",
         "0.014098706",
         "-14.458",
         "47.634",
         "20.449",
         "0",
         "A_43"
        ],
        [
         "2836",
         "A",
         "44",
         "T",
         "0.0012490222",
         "-18.287",
         "49.37",
         "19.51",
         "0",
         "A_44"
        ],
        [
         "2837",
         "A",
         "45",
         "K",
         "0.012634724",
         "-17.147",
         "49.948",
         "24.86",
         "0",
         "A_45"
        ],
        [
         "2838",
         "A",
         "46",
         "T",
         "0.019516127",
         "-13.095",
         "50.986",
         "22.553",
         "0",
         "A_46"
        ],
        [
         "2839",
         "A",
         "47",
         "G",
         "0.0035966702",
         "-12.799",
         "52.055",
         "18.945",
         "0",
         "A_47"
        ],
        [
         "2840",
         "A",
         "48",
         "L",
         "0.020840876",
         "-10.116",
         "50.271",
         "19.366",
         "0",
         "A_48"
        ],
        [
         "2841",
         "A",
         "49",
         "R",
         "0.1271371",
         "-9.541",
         "46.805",
         "14.471",
         "0",
         "A_49"
        ],
        [
         "2842",
         "A",
         "50",
         "V",
         "0.099768214",
         "-9.524",
         "43.961",
         "18.239",
         "0",
         "A_50"
        ],
        [
         "2843",
         "A",
         "51",
         "A",
         "0.85270864",
         "-7.906",
         "40.462",
         "18.581",
         "2",
         "A_51"
        ],
        [
         "2844",
         "A",
         "52",
         "V",
         "0.106220976",
         "-10.776",
         "37.662",
         "18.737",
         "0",
         "A_52"
        ],
        [
         "2845",
         "A",
         "53",
         "K",
         "0.9715115",
         "-7.546",
         "33.385",
         "20.729",
         "2",
         "A_53"
        ],
        [
         "2846",
         "A",
         "54",
         "K",
         "0.08911832",
         "-12.452",
         "30.099",
         "19.44",
         "0",
         "A_54"
        ],
        [
         "2847",
         "A",
         "55",
         "L",
         "0.31626505",
         "-9.527",
         "28.636",
         "22.763",
         "0",
         "A_55"
        ],
        [
         "2848",
         "A",
         "56",
         "S",
         "0.2512265",
         "-9.883",
         "25.118",
         "19.969",
         "0",
         "A_56"
        ],
        [
         "2849",
         "A",
         "57",
         "R",
         "0.054226186",
         "-11.548",
         "21.161",
         "20.581",
         "0",
         "A_57"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 327
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chain</th>\n",
       "      <th>resi</th>\n",
       "      <th>resn</th>\n",
       "      <th>p(bind)</th>\n",
       "      <th>center_of_mass_x</th>\n",
       "      <th>center_of_mass_y</th>\n",
       "      <th>center_of_mass_z</th>\n",
       "      <th>pocket</th>\n",
       "      <th>residue_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>R</td>\n",
       "      <td>0.039529</td>\n",
       "      <td>-24.874</td>\n",
       "      <td>37.998</td>\n",
       "      <td>29.439</td>\n",
       "      <td>0</td>\n",
       "      <td>A_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>A</td>\n",
       "      <td>6</td>\n",
       "      <td>P</td>\n",
       "      <td>0.034048</td>\n",
       "      <td>-23.549</td>\n",
       "      <td>40.555</td>\n",
       "      <td>27.539</td>\n",
       "      <td>0</td>\n",
       "      <td>A_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>A</td>\n",
       "      <td>7</td>\n",
       "      <td>T</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>-26.034</td>\n",
       "      <td>40.724</td>\n",
       "      <td>23.731</td>\n",
       "      <td>0</td>\n",
       "      <td>A_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>A</td>\n",
       "      <td>8</td>\n",
       "      <td>F</td>\n",
       "      <td>0.006006</td>\n",
       "      <td>-23.113</td>\n",
       "      <td>37.045</td>\n",
       "      <td>23.328</td>\n",
       "      <td>0</td>\n",
       "      <td>A_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>A</td>\n",
       "      <td>9</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>-22.688</td>\n",
       "      <td>38.464</td>\n",
       "      <td>17.061</td>\n",
       "      <td>0</td>\n",
       "      <td>A_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3122</th>\n",
       "      <td>A</td>\n",
       "      <td>348</td>\n",
       "      <td>F</td>\n",
       "      <td>0.029051</td>\n",
       "      <td>-11.070</td>\n",
       "      <td>40.469</td>\n",
       "      <td>33.250</td>\n",
       "      <td>0</td>\n",
       "      <td>A_348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123</th>\n",
       "      <td>A</td>\n",
       "      <td>349</td>\n",
       "      <td>V</td>\n",
       "      <td>0.026582</td>\n",
       "      <td>-10.757</td>\n",
       "      <td>43.710</td>\n",
       "      <td>35.590</td>\n",
       "      <td>0</td>\n",
       "      <td>A_349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>A</td>\n",
       "      <td>350</td>\n",
       "      <td>P</td>\n",
       "      <td>0.035559</td>\n",
       "      <td>-11.266</td>\n",
       "      <td>45.571</td>\n",
       "      <td>32.610</td>\n",
       "      <td>0</td>\n",
       "      <td>A_350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125</th>\n",
       "      <td>A</td>\n",
       "      <td>351</td>\n",
       "      <td>P</td>\n",
       "      <td>0.034058</td>\n",
       "      <td>-8.268</td>\n",
       "      <td>47.652</td>\n",
       "      <td>31.057</td>\n",
       "      <td>0</td>\n",
       "      <td>A_351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>A</td>\n",
       "      <td>352</td>\n",
       "      <td>P</td>\n",
       "      <td>0.026103</td>\n",
       "      <td>-7.204</td>\n",
       "      <td>51.013</td>\n",
       "      <td>32.328</td>\n",
       "      <td>0</td>\n",
       "      <td>A_352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chain  resi resn   p(bind)  center_of_mass_x  center_of_mass_y  \\\n",
       "2800     A     5    R  0.039529           -24.874            37.998   \n",
       "2801     A     6    P  0.034048           -23.549            40.555   \n",
       "2802     A     7    T  0.003536           -26.034            40.724   \n",
       "2803     A     8    F  0.006006           -23.113            37.045   \n",
       "2804     A     9    Y  0.001696           -22.688            38.464   \n",
       "...    ...   ...  ...       ...               ...               ...   \n",
       "3122     A   348    F  0.029051           -11.070            40.469   \n",
       "3123     A   349    V  0.026582           -10.757            43.710   \n",
       "3124     A   350    P  0.035559           -11.266            45.571   \n",
       "3125     A   351    P  0.034058            -8.268            47.652   \n",
       "3126     A   352    P  0.026103            -7.204            51.013   \n",
       "\n",
       "      center_of_mass_z  pocket residue_id  \n",
       "2800            29.439       0        A_5  \n",
       "2801            27.539       0        A_6  \n",
       "2802            23.731       0        A_7  \n",
       "2803            23.328       0        A_8  \n",
       "2804            17.061       0        A_9  \n",
       "...                ...     ...        ...  \n",
       "3122            33.250       0      A_348  \n",
       "3123            35.590       0      A_349  \n",
       "3124            32.610       0      A_350  \n",
       "3125            31.057       0      A_351  \n",
       "3126            32.328       0      A_352  \n",
       "\n",
       "[327 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kmean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "chain",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": " residue_label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": " residue_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": " score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": " zscore",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": " probability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": " pocket",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "614e06d0-fee8-4451-bf68-2ced0beef188",
       "rows": [
        [
         "0",
         "A",
         "5",
         " ARG",
         "0.316",
         "-0.2033",
         "0.0153",
         "0"
        ],
        [
         "1",
         "A",
         "6",
         " PRO",
         "0.3657",
         "-0.1756",
         "0.02",
         "5"
        ],
        [
         "2",
         "A",
         "7",
         " THR",
         "0.1179",
         "-0.3138",
         "0.003",
         "0"
        ],
        [
         "3",
         "A",
         "8",
         " PHE",
         "0.2493",
         "-0.2405",
         "0.0101",
         "0"
        ],
        [
         "4",
         "A",
         "9",
         " TYR",
         "0.0882",
         "-0.3303",
         "0.002",
         "0"
        ],
        [
         "5",
         "A",
         "10",
         " ARG",
         "0.0585",
         "-0.3469",
         "0.0012",
         "0"
        ],
        [
         "6",
         "A",
         "11",
         " GLN",
         "0.0523",
         "-0.3503",
         "0.0011",
         "0"
        ],
        [
         "7",
         "A",
         "12",
         " GLU",
         "0.0057",
         "-0.3763",
         "0.0003",
         "0"
        ],
        [
         "8",
         "A",
         "13",
         " LEU",
         "0.3854",
         "-0.1646",
         "0.022",
         "0"
        ],
        [
         "9",
         "A",
         "14",
         " ASN",
         "0.4026",
         "-0.155",
         "0.0238",
         "0"
        ],
        [
         "10",
         "A",
         "15",
         " LYS",
         "0.0825",
         "-0.3335",
         "0.0018",
         "0"
        ],
        [
         "11",
         "A",
         "16",
         " THR",
         "0.5108",
         "-0.0947",
         "0.0374",
         "0"
        ],
        [
         "12",
         "A",
         "17",
         " ILE",
         "0.1026",
         "-0.3223",
         "0.0024",
         "0"
        ],
        [
         "13",
         "A",
         "18",
         " TRP",
         "0.3861",
         "-0.1642",
         "0.0221",
         "0"
        ],
        [
         "14",
         "A",
         "19",
         " GLU",
         "0.0327",
         "-0.3612",
         "0.0007",
         "0"
        ],
        [
         "15",
         "A",
         "20",
         " VAL",
         "0.0014",
         "-0.3787",
         "0.0002",
         "0"
        ],
        [
         "16",
         "A",
         "21",
         " PRO",
         "0.2407",
         "-0.2453",
         "0.0095",
         "5"
        ],
        [
         "17",
         "A",
         "22",
         " GLU",
         "0.0697",
         "-0.3406",
         "0.0015",
         "0"
        ],
        [
         "18",
         "A",
         "23",
         " ARG",
         "0.3706",
         "-0.1729",
         "0.0205",
         "5"
        ],
        [
         "19",
         "A",
         "24",
         " TYR",
         "0.2368",
         "-0.2475",
         "0.0092",
         "0"
        ],
        [
         "20",
         "A",
         "25",
         " GLN",
         "0.0873",
         "-0.3308",
         "0.0019",
         "0"
        ],
        [
         "21",
         "A",
         "26",
         " ASN",
         "0.0821",
         "-0.3337",
         "0.0018",
         "0"
        ],
        [
         "22",
         "A",
         "27",
         " LEU",
         "0.0358",
         "-0.3595",
         "0.0007",
         "0"
        ],
        [
         "23",
         "A",
         "28",
         " SER",
         "0.2074",
         "-0.2639",
         "0.0073",
         "0"
        ],
        [
         "24",
         "A",
         "29",
         " PRO",
         "0.3842",
         "-0.1653",
         "0.0219",
         "0"
        ],
        [
         "25",
         "A",
         "30",
         " VAL",
         "1.3775",
         "0.3883",
         "0.2472",
         "1"
        ],
        [
         "26",
         "A",
         "31",
         " GLY",
         "0.5312",
         "-0.0834",
         "0.0405",
         "0"
        ],
        [
         "27",
         "A",
         "32",
         " SER",
         "0.588",
         "-0.0517",
         "0.0494",
         "1"
        ],
        [
         "28",
         "A",
         "36",
         " GLY",
         "0.9866",
         "0.1705",
         "0.1374",
         "0"
        ],
        [
         "29",
         "A",
         "37",
         " SER",
         "0.5386",
         "-0.0793",
         "0.0416",
         "0"
        ],
        [
         "30",
         "A",
         "38",
         " VAL",
         "2.4509",
         "0.9867",
         "0.5122",
         "1"
        ],
        [
         "31",
         "A",
         "39",
         " CYS",
         "0.3501",
         "-0.1843",
         "0.0185",
         "0"
        ],
        [
         "32",
         "A",
         "40",
         " ALA",
         "0.053",
         "-0.3499",
         "0.0011",
         "0"
        ],
        [
         "33",
         "A",
         "41",
         " ALA",
         "0.0057",
         "-0.3763",
         "0.0003",
         "0"
        ],
        [
         "34",
         "A",
         "42",
         " PHE",
         "0.1327",
         "-0.3055",
         "0.0036",
         "0"
        ],
        [
         "35",
         "A",
         "43",
         " ASP",
         "0.1567",
         "-0.2921",
         "0.0046",
         "0"
        ],
        [
         "36",
         "A",
         "44",
         " THR",
         "0.1022",
         "-0.3225",
         "0.0024",
         "0"
        ],
        [
         "37",
         "A",
         "45",
         " LYS",
         "0.2109",
         "-0.2619",
         "0.0075",
         "0"
        ],
        [
         "38",
         "A",
         "46",
         " THR",
         "0.1658",
         "-0.2871",
         "0.005",
         "0"
        ],
        [
         "39",
         "A",
         "47",
         " GLY",
         "0.0427",
         "-0.3557",
         "0.0009",
         "0"
        ],
        [
         "40",
         "A",
         "48",
         " LEU",
         "0.1074",
         "-0.3196",
         "0.0026",
         "0"
        ],
        [
         "41",
         "A",
         "49",
         " ARG",
         "0.1082",
         "-0.3191",
         "0.0026",
         "0"
        ],
        [
         "42",
         "A",
         "50",
         " VAL",
         "0.1161",
         "-0.3148",
         "0.0029",
         "0"
        ],
        [
         "43",
         "A",
         "51",
         " ALA",
         "1.8704",
         "0.6631",
         "0.3816",
         "1"
        ],
        [
         "44",
         "A",
         "52",
         " VAL",
         "0.7175",
         "0.0205",
         "0.0733",
         "0"
        ],
        [
         "45",
         "A",
         "53",
         " LYS",
         "1.4833",
         "0.4474",
         "0.2779",
         "1"
        ],
        [
         "46",
         "A",
         "54",
         " LYS",
         "0.4126",
         "-0.1495",
         "0.025",
         "0"
        ],
        [
         "47",
         "A",
         "55",
         " LEU",
         "1.123",
         "0.2465",
         "0.1746",
         "0"
        ],
        [
         "48",
         "A",
         "56",
         " SER",
         "1.1975",
         "0.288",
         "0.1955",
         "0"
        ],
        [
         "49",
         "A",
         "57",
         " ARG",
         "0.7359",
         "0.0307",
         "0.0771",
         "0"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 327
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chain</th>\n",
       "      <th>residue_label</th>\n",
       "      <th>residue_name</th>\n",
       "      <th>score</th>\n",
       "      <th>zscore</th>\n",
       "      <th>probability</th>\n",
       "      <th>pocket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.3160</td>\n",
       "      <td>-0.2033</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>6</td>\n",
       "      <td>PRO</td>\n",
       "      <td>0.3657</td>\n",
       "      <td>-0.1756</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>7</td>\n",
       "      <td>THR</td>\n",
       "      <td>0.1179</td>\n",
       "      <td>-0.3138</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>8</td>\n",
       "      <td>PHE</td>\n",
       "      <td>0.2493</td>\n",
       "      <td>-0.2405</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>9</td>\n",
       "      <td>TYR</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>-0.3303</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>A</td>\n",
       "      <td>348</td>\n",
       "      <td>PHE</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>-0.2940</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>A</td>\n",
       "      <td>349</td>\n",
       "      <td>VAL</td>\n",
       "      <td>0.1597</td>\n",
       "      <td>-0.2904</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>A</td>\n",
       "      <td>350</td>\n",
       "      <td>PRO</td>\n",
       "      <td>0.1545</td>\n",
       "      <td>-0.2934</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>A</td>\n",
       "      <td>351</td>\n",
       "      <td>PRO</td>\n",
       "      <td>0.2739</td>\n",
       "      <td>-0.2268</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>A</td>\n",
       "      <td>352</td>\n",
       "      <td>PRO</td>\n",
       "      <td>0.1469</td>\n",
       "      <td>-0.2976</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    chain   residue_label  residue_name   score   zscore   probability  \\\n",
       "0       A               5           ARG  0.3160  -0.2033        0.0153   \n",
       "1       A               6           PRO  0.3657  -0.1756        0.0200   \n",
       "2       A               7           THR  0.1179  -0.3138        0.0030   \n",
       "3       A               8           PHE  0.2493  -0.2405        0.0101   \n",
       "4       A               9           TYR  0.0882  -0.3303        0.0020   \n",
       "..    ...             ...           ...     ...      ...           ...   \n",
       "322     A             348           PHE  0.1533  -0.2940        0.0045   \n",
       "323     A             349           VAL  0.1597  -0.2904        0.0048   \n",
       "324     A             350           PRO  0.1545  -0.2934        0.0045   \n",
       "325     A             351           PRO  0.2739  -0.2268        0.0119   \n",
       "326     A             352           PRO  0.1469  -0.2976        0.0042   \n",
       "\n",
       "      pocket  \n",
       "0          0  \n",
       "1          5  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "..       ...  \n",
       "322        5  \n",
       "323        0  \n",
       "324        0  \n",
       "325        4  \n",
       "326        0  \n",
       "\n",
       "[327 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residues_file = \"/Users/nicha/dev/p2rank/distro/test_output/predict_3hvc_stripped/3hvc_stripped.pdb_residues.csv\"\n",
    "# rename the column name remove all the space\n",
    "residue_df = pd.read_csv(residues_file)\n",
    "residue_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ligand Centers: {'A_GG5_361': (-3.732, 37.54, 19.149), 'A_GG5_362': (24.619, 22.289, 26.946)}\n",
      "Ligand Diameters: {'A_GG5_361': 8.652, 'A_GG5_362': 8.632}\n",
      "Computed Grid Sizes: {'A_GG5_361': 22.922, 'A_GG5_362': 22.906}\n"
     ]
    }
   ],
   "source": [
    "# Compute ligand centers and diameters\n",
    "ligand_centers = calculate_ligand_centers(pdb_file)\n",
    "ligand_diameters = calculate_ligand_diameter(pdb_file)\n",
    "\n",
    "# Compute grid sizes\n",
    "grid_sizes = {lig_id: calculate_grid_size_ligand(diameter) for lig_id, diameter in ligand_diameters.items()}\n",
    "\n",
    "# Print results\n",
    "print(\"Ligand Centers:\", ligand_centers)\n",
    "print(\"Ligand Diameters:\", ligand_diameters)\n",
    "print(\"Computed Grid Sizes:\", grid_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box for A_GG5_361: Min=[-15.193000000000001, 26.079, 7.688000000000001], Max=[7.729, 49.001, 30.61]\n",
      "Bounding box for A_GG5_362: Min=[13.166, 10.836000000000002, 15.493000000000002], Max=[36.072, 33.742000000000004, 38.399]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A_GG5_361': {'min': [-15.193000000000001, 26.079, 7.688000000000001],\n",
       "  'max': [7.729, 49.001, 30.61]},\n",
       " 'A_GG5_362': {'min': [13.166, 10.836000000000002, 15.493000000000002],\n",
       "  'max': [36.072, 33.742000000000004, 38.399]}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "define_bounding_box_ligand(ligand_centers, ligand_diameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "chain",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "resi",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "resn",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "p(bind)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "center_of_mass_x",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "center_of_mass_y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "center_of_mass_z",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pocket",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "residue_id",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9cd207da-7f3e-4100-a490-4e2b5762403e",
       "rows": [
        [
         "2800",
         "A",
         "5",
         "R",
         "0.039529245",
         "-24.874",
         "37.998",
         "29.439",
         "0",
         "A_5"
        ],
        [
         "2801",
         "A",
         "6",
         "P",
         "0.034047898",
         "-23.549",
         "40.555",
         "27.539",
         "0",
         "A_6"
        ],
        [
         "2802",
         "A",
         "7",
         "T",
         "0.0035355922",
         "-26.034",
         "40.724",
         "23.731",
         "0",
         "A_7"
        ],
        [
         "2803",
         "A",
         "8",
         "F",
         "0.0060059493",
         "-23.113",
         "37.045",
         "23.328",
         "0",
         "A_8"
        ],
        [
         "2804",
         "A",
         "9",
         "Y",
         "0.0016957241",
         "-22.688",
         "38.464",
         "17.061",
         "0",
         "A_9"
        ],
        [
         "2805",
         "A",
         "10",
         "R",
         "0.00059366686",
         "-24.025",
         "31.304",
         "16.256",
         "0",
         "A_10"
        ],
        [
         "2806",
         "A",
         "11",
         "Q",
         "0.0013087553",
         "-20.528",
         "34.603",
         "13.067",
         "0",
         "A_11"
        ],
        [
         "2807",
         "A",
         "12",
         "E",
         "0.00073863164",
         "-19.911",
         "29.518",
         "10.198",
         "0",
         "A_12"
        ],
        [
         "2808",
         "A",
         "13",
         "L",
         "0.0032519058",
         "-16.129",
         "32.4",
         "10.427",
         "0",
         "A_13"
        ],
        [
         "2809",
         "A",
         "14",
         "N",
         "0.022676304",
         "-13.359",
         "29.519",
         "8.141",
         "0",
         "A_14"
        ],
        [
         "2810",
         "A",
         "15",
         "K",
         "0.0076594716",
         "-15.609",
         "24.677",
         "8.618",
         "0",
         "A_15"
        ],
        [
         "2811",
         "A",
         "16",
         "T",
         "0.017679509",
         "-15.361",
         "28.27",
         "13.063",
         "0",
         "A_16"
        ],
        [
         "2812",
         "A",
         "17",
         "I",
         "0.0011228818",
         "-19.02",
         "28.658",
         "15.492",
         "0",
         "A_17"
        ],
        [
         "2813",
         "A",
         "18",
         "W",
         "0.016597053",
         "-15.832",
         "32.995",
         "15.997",
         "0",
         "A_18"
        ],
        [
         "2814",
         "A",
         "19",
         "E",
         "0.002587375",
         "-21.037",
         "32.215",
         "20.265",
         "0",
         "A_19"
        ],
        [
         "2815",
         "A",
         "20",
         "V",
         "0.006985143",
         "-19.342",
         "37.466",
         "20.04",
         "0",
         "A_20"
        ],
        [
         "2816",
         "A",
         "21",
         "P",
         "0.0070247455",
         "-19.974",
         "40.13",
         "22.321",
         "0",
         "A_21"
        ],
        [
         "2817",
         "A",
         "22",
         "E",
         "0.0010002918",
         "-23.862",
         "43.381",
         "20.409",
         "0",
         "A_22"
        ],
        [
         "2818",
         "A",
         "23",
         "R",
         "0.0072041894",
         "-17.737",
         "45.257",
         "22.792",
         "0",
         "A_23"
        ],
        [
         "2819",
         "A",
         "24",
         "Y",
         "0.01384173",
         "-16.317",
         "42.737",
         "20.551",
         "0",
         "A_24"
        ],
        [
         "2820",
         "A",
         "25",
         "Q",
         "0.0018480881",
         "-19.296",
         "44.127",
         "15.04",
         "0",
         "A_25"
        ],
        [
         "2821",
         "A",
         "26",
         "N",
         "0.00634375",
         "-15.915",
         "43.533",
         "10.848",
         "0",
         "A_26"
        ],
        [
         "2822",
         "A",
         "27",
         "L",
         "0.012526404",
         "-15.58",
         "39.286",
         "13.022",
         "0",
         "A_27"
        ],
        [
         "2823",
         "A",
         "28",
         "S",
         "0.048782405",
         "-11.917",
         "39.147",
         "10.098",
         "0",
         "A_28"
        ],
        [
         "2824",
         "A",
         "29",
         "P",
         "0.053905353",
         "-10.484",
         "35.946",
         "9.326",
         "0",
         "A_29"
        ],
        [
         "2825",
         "A",
         "30",
         "V",
         "0.34186763",
         "-5.915",
         "36.685",
         "10.807",
         "0",
         "A_30"
        ],
        [
         "2826",
         "A",
         "31",
         "G",
         "0.5572299",
         "-5.722",
         "33.118",
         "11.88",
         "1",
         "A_31"
        ],
        [
         "2827",
         "A",
         "32",
         "S",
         "0.20038687",
         "-4.304",
         "30.404",
         "13.602",
         "0",
         "A_32"
        ],
        [
         "2828",
         "A",
         "36",
         "G",
         "0.76669675",
         "-6.642",
         "28.671",
         "17.527",
         "2",
         "A_36"
        ],
        [
         "2829",
         "A",
         "37",
         "S",
         "0.10781854",
         "-9.011",
         "30.835",
         "15.838",
         "0",
         "A_37"
        ],
        [
         "2830",
         "A",
         "38",
         "V",
         "0.88128424",
         "-7.559",
         "34.871",
         "15.162",
         "2",
         "A_38"
        ],
        [
         "2831",
         "A",
         "39",
         "C",
         "0.047566254",
         "-11.024",
         "37.022",
         "14.171",
         "0",
         "A_39"
        ],
        [
         "2832",
         "A",
         "40",
         "A",
         "0.20422311",
         "-10.403",
         "40.759",
         "13.184",
         "0",
         "A_40"
        ],
        [
         "2833",
         "A",
         "41",
         "A",
         "0.041072745",
         "-12.19",
         "43.399",
         "15.153",
         "0",
         "A_41"
        ],
        [
         "2834",
         "A",
         "42",
         "F",
         "0.0077128354",
         "-14.505",
         "48.163",
         "15.779",
         "0",
         "A_42"
        ],
        [
         "2835",
         "A",
         "43",
         "D",
         "0.014098706",
         "-14.458",
         "47.634",
         "20.449",
         "0",
         "A_43"
        ],
        [
         "2836",
         "A",
         "44",
         "T",
         "0.0012490222",
         "-18.287",
         "49.37",
         "19.51",
         "0",
         "A_44"
        ],
        [
         "2837",
         "A",
         "45",
         "K",
         "0.012634724",
         "-17.147",
         "49.948",
         "24.86",
         "0",
         "A_45"
        ],
        [
         "2838",
         "A",
         "46",
         "T",
         "0.019516127",
         "-13.095",
         "50.986",
         "22.553",
         "0",
         "A_46"
        ],
        [
         "2839",
         "A",
         "47",
         "G",
         "0.0035966702",
         "-12.799",
         "52.055",
         "18.945",
         "0",
         "A_47"
        ],
        [
         "2840",
         "A",
         "48",
         "L",
         "0.020840876",
         "-10.116",
         "50.271",
         "19.366",
         "0",
         "A_48"
        ],
        [
         "2841",
         "A",
         "49",
         "R",
         "0.1271371",
         "-9.541",
         "46.805",
         "14.471",
         "0",
         "A_49"
        ],
        [
         "2842",
         "A",
         "50",
         "V",
         "0.099768214",
         "-9.524",
         "43.961",
         "18.239",
         "0",
         "A_50"
        ],
        [
         "2843",
         "A",
         "51",
         "A",
         "0.85270864",
         "-7.906",
         "40.462",
         "18.581",
         "2",
         "A_51"
        ],
        [
         "2844",
         "A",
         "52",
         "V",
         "0.106220976",
         "-10.776",
         "37.662",
         "18.737",
         "0",
         "A_52"
        ],
        [
         "2845",
         "A",
         "53",
         "K",
         "0.9715115",
         "-7.546",
         "33.385",
         "20.729",
         "2",
         "A_53"
        ],
        [
         "2846",
         "A",
         "54",
         "K",
         "0.08911832",
         "-12.452",
         "30.099",
         "19.44",
         "0",
         "A_54"
        ],
        [
         "2847",
         "A",
         "55",
         "L",
         "0.31626505",
         "-9.527",
         "28.636",
         "22.763",
         "0",
         "A_55"
        ],
        [
         "2848",
         "A",
         "56",
         "S",
         "0.2512265",
         "-9.883",
         "25.118",
         "19.969",
         "0",
         "A_56"
        ],
        [
         "2849",
         "A",
         "57",
         "R",
         "0.054226186",
         "-11.548",
         "21.161",
         "20.581",
         "0",
         "A_57"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 327
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chain</th>\n",
       "      <th>resi</th>\n",
       "      <th>resn</th>\n",
       "      <th>p(bind)</th>\n",
       "      <th>center_of_mass_x</th>\n",
       "      <th>center_of_mass_y</th>\n",
       "      <th>center_of_mass_z</th>\n",
       "      <th>pocket</th>\n",
       "      <th>residue_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>R</td>\n",
       "      <td>0.039529</td>\n",
       "      <td>-24.874</td>\n",
       "      <td>37.998</td>\n",
       "      <td>29.439</td>\n",
       "      <td>0</td>\n",
       "      <td>A_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>A</td>\n",
       "      <td>6</td>\n",
       "      <td>P</td>\n",
       "      <td>0.034048</td>\n",
       "      <td>-23.549</td>\n",
       "      <td>40.555</td>\n",
       "      <td>27.539</td>\n",
       "      <td>0</td>\n",
       "      <td>A_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>A</td>\n",
       "      <td>7</td>\n",
       "      <td>T</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>-26.034</td>\n",
       "      <td>40.724</td>\n",
       "      <td>23.731</td>\n",
       "      <td>0</td>\n",
       "      <td>A_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>A</td>\n",
       "      <td>8</td>\n",
       "      <td>F</td>\n",
       "      <td>0.006006</td>\n",
       "      <td>-23.113</td>\n",
       "      <td>37.045</td>\n",
       "      <td>23.328</td>\n",
       "      <td>0</td>\n",
       "      <td>A_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>A</td>\n",
       "      <td>9</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>-22.688</td>\n",
       "      <td>38.464</td>\n",
       "      <td>17.061</td>\n",
       "      <td>0</td>\n",
       "      <td>A_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3122</th>\n",
       "      <td>A</td>\n",
       "      <td>348</td>\n",
       "      <td>F</td>\n",
       "      <td>0.029051</td>\n",
       "      <td>-11.070</td>\n",
       "      <td>40.469</td>\n",
       "      <td>33.250</td>\n",
       "      <td>0</td>\n",
       "      <td>A_348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123</th>\n",
       "      <td>A</td>\n",
       "      <td>349</td>\n",
       "      <td>V</td>\n",
       "      <td>0.026582</td>\n",
       "      <td>-10.757</td>\n",
       "      <td>43.710</td>\n",
       "      <td>35.590</td>\n",
       "      <td>0</td>\n",
       "      <td>A_349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>A</td>\n",
       "      <td>350</td>\n",
       "      <td>P</td>\n",
       "      <td>0.035559</td>\n",
       "      <td>-11.266</td>\n",
       "      <td>45.571</td>\n",
       "      <td>32.610</td>\n",
       "      <td>0</td>\n",
       "      <td>A_350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125</th>\n",
       "      <td>A</td>\n",
       "      <td>351</td>\n",
       "      <td>P</td>\n",
       "      <td>0.034058</td>\n",
       "      <td>-8.268</td>\n",
       "      <td>47.652</td>\n",
       "      <td>31.057</td>\n",
       "      <td>0</td>\n",
       "      <td>A_351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>A</td>\n",
       "      <td>352</td>\n",
       "      <td>P</td>\n",
       "      <td>0.026103</td>\n",
       "      <td>-7.204</td>\n",
       "      <td>51.013</td>\n",
       "      <td>32.328</td>\n",
       "      <td>0</td>\n",
       "      <td>A_352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chain  resi resn   p(bind)  center_of_mass_x  center_of_mass_y  \\\n",
       "2800     A     5    R  0.039529           -24.874            37.998   \n",
       "2801     A     6    P  0.034048           -23.549            40.555   \n",
       "2802     A     7    T  0.003536           -26.034            40.724   \n",
       "2803     A     8    F  0.006006           -23.113            37.045   \n",
       "2804     A     9    Y  0.001696           -22.688            38.464   \n",
       "...    ...   ...  ...       ...               ...               ...   \n",
       "3122     A   348    F  0.029051           -11.070            40.469   \n",
       "3123     A   349    V  0.026582           -10.757            43.710   \n",
       "3124     A   350    P  0.035559           -11.266            45.571   \n",
       "3125     A   351    P  0.034058            -8.268            47.652   \n",
       "3126     A   352    P  0.026103            -7.204            51.013   \n",
       "\n",
       "      center_of_mass_z  pocket residue_id  \n",
       "2800            29.439       0        A_5  \n",
       "2801            27.539       0        A_6  \n",
       "2802            23.731       0        A_7  \n",
       "2803            23.328       0        A_8  \n",
       "2804            17.061       0        A_9  \n",
       "...                ...     ...        ...  \n",
       "3122            33.250       0      A_348  \n",
       "3123            35.590       0      A_349  \n",
       "3124            32.610       0      A_350  \n",
       "3125            31.057       0      A_351  \n",
       "3126            32.328       0      A_352  \n",
       "\n",
       "[327 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_residue_file(residue_file, pdb_file):\n",
    "    \"\"\"\n",
    "    Reads a PDB file and updates a DataFrame with residue center of mass.\n",
    "\n",
    "    Args:\n",
    "        residue_file (str): Path to the residue CSV file.\n",
    "        pdb_file (str): Path to the PDB file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with center of mass information.\n",
    "    \"\"\"\n",
    "    residues_df = pd.read_csv(residue_file)\n",
    "    \n",
    "    #remove the white space in the column name\n",
    "    residues_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "    #print(residues_df.columns)\n",
    "    \n",
    "    # Rename columns residue_label to resi\n",
    "    residues_df.rename(columns={'residue_label':'resi'}, inplace=True)\n",
    "    #print(residues_df.columns)\n",
    "    \n",
    "    \n",
    "    for index, row in residues_df.iterrows():\n",
    "        residue_number = row[\"resi\"]\n",
    "        chain_id = row[\"chain\"].strip()\n",
    "        coordinates = extract_residue_coordinates(pdb_file, residue_number, chain_id)\n",
    "        if coordinates:\n",
    "            center_of_mass = calculate_weighted_center_of_mass(coordinates)\n",
    "            residues_df.loc[index, \"resn_coordinates\"] = str(coordinates)\n",
    "            residues_df.loc[index, [\"center_of_mass_x\", \"center_of_mass_y\", \"center_of_mass_z\"]] = center_of_mass\n",
    "        else:\n",
    "            print(f\"Residue {residue_number} in chain {chain_id} not found in {pdb_file}.\")\n",
    "\n",
    "    return residues_df\n",
    "\n",
    "# grid box preidction from p2rank\n",
    "\n",
    "def calculate_size_residues_df(residue_df, pocket_id):\n",
    "    \"\"\"\n",
    "    Calculates the size of a binding pocket based on residue coordinates.\n",
    "\n",
    "    Args:\n",
    "        residue_df (pd.DataFrame): DataFrame containing residue information.\n",
    "        pocket_id (int): ID of the pocket to analyze.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing pocket size and bounding box dimensions.\n",
    "    \"\"\"\n",
    "\n",
    "    pocket_id = 1\n",
    "    selected_residues = residue_df.loc[residue_df[\"pocket\"] == pocket_id]\n",
    "    selection_name=\"cluster_selection\"\n",
    "\n",
    "    if selected_residues.empty:\n",
    "            print(f\"⚠️ No residues found for cluster {pocket_id} in column 'pocket'\")\n",
    "            return None\n",
    "        \n",
    "\n",
    "    # Construct a PyMOL selection string\n",
    "    selection_string = \" or \".join(\n",
    "            [f\"(chain {row['chain']} and resi {row['resi']})\" for _, row in selected_residues.iterrows()]\n",
    "        )#\n",
    "\n",
    "    # Check if PyMOL is available\n",
    "    try:\n",
    "        cmd.select(selection_name, selection_string)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ PyMOL selection failed: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Compute the bounding box\n",
    "    min_coords = selected_residues[['center_of_mass_x', 'center_of_mass_y', 'center_of_mass_z']].min().to_numpy()\n",
    "    max_coords = selected_residues[['center_of_mass_x', 'center_of_mass_y', 'center_of_mass_z']].max().to_numpy()\n",
    "\n",
    "    # Convert coordinates to float for compatibility\n",
    "    min_coords = np.array([float(coord) for coord in min_coords])\n",
    "    max_coords = np.array([float(coord) for coord in max_coords])\n",
    "\n",
    "    # Add pseudoatoms for visualization\n",
    "    try:\n",
    "        cmd.pseudoatom(f\"{selection_name}_box_min\", pos=min_coords.tolist(), color=\"blue\")\n",
    "        cmd.pseudoatom(f\"{selection_name}_box_max\", pos=max_coords.tolist(), color=\"red\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to create pseudoatoms in PyMOL: {e}\")\n",
    "        \n",
    "    #print(f\"📦 Bounding box: Min={min_coords.tolist()}, Max={max_coords.tolist()}\")\n",
    "    \n",
    "    #euclidean distance\n",
    "    size = round(np.linalg.norm(max_coords - min_coords),3)\n",
    "    \n",
    "    return {\"min\": min_coords, \"max\": max_coords, \"size\": size}\n",
    "\n",
    "def calculate_pocket_data(residues_file, pocket_file, pdb_file, pocket_id):\n",
    "    \"\"\"\n",
    "    Processes residue and pocket data, calculates the binding pocket size, \n",
    "    and extracts its center coordinates.\n",
    "\n",
    "    Args:\n",
    "        residues_file (str): Path to the residues CSV file.\n",
    "        pocket_file (str): Path to the pocket predictions CSV file.\n",
    "        pdb_file (str): Path to the PDB file.\n",
    "        pocket_id (int): ID of the pocket to analyze.\n",
    "\n",
    "    Returns:\n",
    "        dict: Contains the center coordinates and size of the pocket.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load and clean residues data\n",
    "    residue_df = pd.read_csv(residues_file)\n",
    "    residue_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "    residue_df = process_residue_file(residues_file, pdb_file)\n",
    "\n",
    "    # Load and clean pocket data\n",
    "    pocket_df = pd.read_csv(pocket_file)\n",
    "    pocket_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "\n",
    "    # Compute binding pocket size\n",
    "    info_binding_pocket = calculate_size_residues_df(residue_df, pocket_id)\n",
    "\n",
    "    # Select pocket-specific residues\n",
    "    selected_pocket = residue_df.loc[residue_df['pocket'] == pocket_id]\n",
    "    \n",
    "    selected_pocket.columns\n",
    "\n",
    "    # Extract center coordinates and size\n",
    "    coordinate = selected_pocket[['center_of_mass_x', 'center_of_mass_y', 'center_of_mass_z']].values[0]\n",
    "    size = info_binding_pocket['size']\n",
    "\n",
    "    return {\n",
    "        \"coordinate\": coordinate,\n",
    "        \"size\": round(size, 3)\n",
    "    }\n",
    "    \n",
    "import os\n",
    "\n",
    "def create_config_autodock(residues_file, pocket_file, pdb_file, pocket_id, output_dir):\n",
    "    \"\"\"\n",
    "    Create an AutoDock configuration file based on pocket data.\n",
    "\n",
    "    Args:\n",
    "        residues_file (str): Path to residues CSV file.\n",
    "        pocket_file (str): Path to pocket file.\n",
    "        pdb_file (str): Path to protein PDB file.\n",
    "        pocket_id (int): ID of the binding pocket.\n",
    "        output_dir (str): Directory to save the config file.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the generated config file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract protein name from PDB file\n",
    "    protein_name = os.path.splitext(os.path.basename(pdb_file))[0]\n",
    "\n",
    "    # Calculate pocket data\n",
    "    result = calculate_pocket_data(residues_file, pocket_file, pdb_file, pocket_id)\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Define config file path\n",
    "    config_file = os.path.join(output_dir, f\"config_{protein_name}_pocket_{pocket_id}.txt\")\n",
    "\n",
    "    # Write the configuration file\n",
    "    with open(config_file, \"w\") as f:\n",
    "        f.write(f\"center_x = {result['coordinate'][0]}\\n\")\n",
    "        f.write(f\"center_y = {result['coordinate'][1]}\\n\")\n",
    "        f.write(f\"center_z = {result['coordinate'][2]}\\n\")\n",
    "        f.write(f\"size_x = {result['size']}\\n\")\n",
    "        f.write(f\"size_y = {result['size']}\\n\")\n",
    "        f.write(f\"size_z = {result['size']}\\n\")\n",
    "        f.write(\"exhaustiveness = 8\\n\")  # Example extra parameter\n",
    "        f.write(\"num_modes = 20\\n\")  # Example docking modes\n",
    "\n",
    "    print(f\"✅ Config file created: {config_file}\")\n",
    "    \n",
    "    return config_file\n",
    "\n",
    " \n",
    "def create_config_ligand_based(pdb_file, output_dir):   \n",
    "    # Compute ligand centers and diameters\n",
    "    ligand_centers = calculate_ligand_centers(pdb_file)\n",
    "    ligand_diameters = calculate_ligand_diameter(pdb_file)\n",
    "\n",
    "    # Compute grid sizes\n",
    "    grid_sizes = {lig_id: calculate_grid_size_ligand(diameter) for lig_id, diameter in ligand_diameters.items()}\n",
    "    \n",
    "     # Ensure output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Define config file path\n",
    "    config_file = os.path.join(output_dir, f\"config_{protein_name}_pocket_{pocket_id}.txt\")\n",
    "\n",
    "    # Write the configuration file\n",
    "    with open(config_file, \"w\") as f:\n",
    "        f.write(f\"center_x = {result['coordinate'][0]}\\n\")\n",
    "        f.write(f\"center_y = {result['coordinate'][1]}\\n\")\n",
    "        f.write(f\"center_z = {result['coordinate'][2]}\\n\")\n",
    "        f.write(f\"size_x = {result['size']}\\n\")\n",
    "        f.write(f\"size_y = {result['size']}\\n\")\n",
    "        f.write(f\"size_z = {result['size']}\\n\")\n",
    "        f.write(\"exhaustiveness = 8\\n\")  # Example extra parameter\n",
    "        f.write(\"num_modes = 20\\n\")  # Example docking modes\n",
    "\n",
    "    print(f\"✅ Config file created: {config_file}\")\n",
    "    \n",
    "    return config_file\n",
    "    \n",
    "    \n",
    "def process_residue_file(residue_file, pdb_file):\n",
    "    \"\"\"\n",
    "    Reads a PDB file and updates a DataFrame with residue center of mass.\n",
    "\n",
    "    Args:\n",
    "        residue_file (str): Path to the residue CSV file.\n",
    "        pdb_file (str): Path to the PDB file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with center of mass information.\n",
    "    \"\"\"\n",
    "    residues_df = pd.read_csv(residue_file)\n",
    "    \n",
    "    #remove the white space in the column name\n",
    "    residues_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "    #print(residues_df.columns)\n",
    "    \n",
    "    # Rename columns residue_label to resi\n",
    "    residues_df.rename(columns={'residue_label':'resi'}, inplace=True)\n",
    "    #print(residues_df.columns)\n",
    "    \n",
    "    \n",
    "    for index, row in residues_df.iterrows():\n",
    "        residue_number = row[\"resi\"]\n",
    "        chain_id = row[\"chain\"].strip()\n",
    "        coordinates = extract_residue_coordinates(pdb_file, residue_number, chain_id)\n",
    "        if coordinates:\n",
    "            center_of_mass = calculate_weighted_center_of_mass(coordinates)\n",
    "            residues_df.loc[index, \"resn_coordinates\"] = str(coordinates)\n",
    "            residues_df.loc[index, [\"center_of_mass_x\", \"center_of_mass_y\", \"center_of_mass_z\"]] = center_of_mass\n",
    "        else:\n",
    "            print(f\"Residue {residue_number} in chain {chain_id} not found in {pdb_file}.\")\n",
    "\n",
    "    return residues_df\n",
    "\n",
    "# grid box preidction from p2rank\n",
    "\n",
    "def calculate_size_residues_df(residue_df, pocket_id):\n",
    "    \"\"\"\n",
    "    Calculates the size of a binding pocket based on residue coordinates.\n",
    "\n",
    "    Args:\n",
    "        residue_df (pd.DataFrame): DataFrame containing residue information.\n",
    "        pocket_id (int): ID of the pocket to analyze.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing pocket size and bounding box dimensions.\n",
    "    \"\"\"\n",
    "\n",
    "    pocket_id = 1\n",
    "    selected_residues = residue_df.loc[residue_df[\"pocket\"] == pocket_id]\n",
    "    selection_name=\"cluster_selection\"\n",
    "\n",
    "    if selected_residues.empty:\n",
    "            print(f\"⚠️ No residues found for cluster {pocket_id} in column 'pocket'\")\n",
    "            return None\n",
    "        \n",
    "\n",
    "    # Construct a PyMOL selection string\n",
    "    selection_string = \" or \".join(\n",
    "            [f\"(chain {row['chain']} and resi {row['resi']})\" for _, row in selected_residues.iterrows()]\n",
    "        )#\n",
    "\n",
    "    # Check if PyMOL is available\n",
    "    try:\n",
    "        cmd.select(selection_name, selection_string)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ PyMOL selection failed: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Compute the bounding box\n",
    "    min_coords = selected_residues[['center_of_mass_x', 'center_of_mass_y', 'center_of_mass_z']].min().to_numpy()\n",
    "    max_coords = selected_residues[['center_of_mass_x', 'center_of_mass_y', 'center_of_mass_z']].max().to_numpy()\n",
    "\n",
    "    # Convert coordinates to float for compatibility\n",
    "    min_coords = np.array([float(coord) for coord in min_coords])\n",
    "    max_coords = np.array([float(coord) for coord in max_coords])\n",
    "\n",
    "    # Add pseudoatoms for visualization\n",
    "    try:\n",
    "        cmd.pseudoatom(f\"{selection_name}_box_min\", pos=min_coords.tolist(), color=\"blue\")\n",
    "        cmd.pseudoatom(f\"{selection_name}_box_max\", pos=max_coords.tolist(), color=\"red\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to create pseudoatoms in PyMOL: {e}\")\n",
    "        \n",
    "    #print(f\"📦 Bounding box: Min={min_coords.tolist()}, Max={max_coords.tolist()}\")\n",
    "    \n",
    "    #euclidean distance\n",
    "    size = round(np.linalg.norm(max_coords - min_coords),3)\n",
    "    \n",
    "    return {\"min\": min_coords, \"max\": max_coords, \"size\": size}\n",
    "\n",
    "def calculate_pocket_data(residues_file, pocket_file, pdb_file, pocket_id):\n",
    "    \"\"\"\n",
    "    Processes residue and pocket data, calculates the binding pocket size, \n",
    "    and extracts its center coordinates.\n",
    "\n",
    "    Args:\n",
    "        residues_file (str): Path to the residues CSV file.\n",
    "        pocket_file (str): Path to the pocket predictions CSV file.\n",
    "        pdb_file (str): Path to the PDB file.\n",
    "        pocket_id (int): ID of the pocket to analyze.\n",
    "\n",
    "    Returns:\n",
    "        dict: Contains the center coordinates and size of the pocket.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load and clean residues data\n",
    "    residue_df = pd.read_csv(residues_file)\n",
    "    residue_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "    residue_df = process_residue_file(residues_file, pdb_file)\n",
    "\n",
    "    # Load and clean pocket data\n",
    "    pocket_df = pd.read_csv(pocket_file)\n",
    "    pocket_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "\n",
    "    # Compute binding pocket size\n",
    "    info_binding_pocket = calculate_size_residues_df(residue_df, pocket_id)\n",
    "\n",
    "    # Select pocket-specific residues\n",
    "    selected_pocket = residue_df.loc[residue_df['pocket'] == pocket_id]\n",
    "    \n",
    "    selected_pocket.columns\n",
    "\n",
    "    # Extract center coordinates and size\n",
    "    coordinate = selected_pocket[['center_of_mass_x', 'center_of_mass_y', 'center_of_mass_z']].values[0]\n",
    "    size = info_binding_pocket['size']\n",
    "\n",
    "    return {\n",
    "        \"coordinate\": coordinate,\n",
    "        \"size\": round(size, 3)\n",
    "    }\n",
    "\n",
    "\n",
    "def create_config_pocket_based(residues_file, pocket_file, pdb_file, pocket_id, output_dir):\n",
    "    \"\"\"\n",
    "    Create an AutoDock configuration file based on pocket data.\n",
    "\n",
    "    Args:\n",
    "        residues_file (str): Path to residues CSV file.\n",
    "        pocket_file (str): Path to pocket file.\n",
    "        pdb_file (str): Path to protein PDB file.\n",
    "        pocket_id (int): ID of the binding pocket.\n",
    "        output_dir (str): Directory to save the config file.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the generated config file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract protein name from PDB file\n",
    "    protein_name = os.path.splitext(os.path.basename(pdb_file))[0]\n",
    "\n",
    "    # Calculate pocket data\n",
    "    result = calculate_pocket_data(residues_file, pocket_file, pdb_file, pocket_id)\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Define config file path\n",
    "    config_file = os.path.join(output_dir, f\"config_{protein_name}_pocket_{pocket_id}.txt\")\n",
    "\n",
    "    # Write the configuration file\n",
    "    with open(config_file, \"w\") as f:\n",
    "        f.write(f\"center_x = {result['coordinate'][0]}\\n\")\n",
    "        f.write(f\"center_y = {result['coordinate'][1]}\\n\")\n",
    "        f.write(f\"center_z = {result['coordinate'][2]}\\n\")\n",
    "        f.write(f\"size_x = {result['size']}\\n\")\n",
    "        f.write(f\"size_y = {result['size']}\\n\")\n",
    "        f.write(f\"size_z = {result['size']}\\n\")\n",
    "        f.write(\"exhaustiveness = 8\\n\")  # Example extra parameter\n",
    "        f.write(\"num_modes = 20\\n\")  # Example docking modes\n",
    "\n",
    "    print(f\"✅ Config file created: {config_file}\")\n",
    "    \n",
    "    return config_file\n",
    "\n",
    " \n",
    "def create_config_ligand_based(pdb_file, output_dir):\n",
    "    \"\"\"\n",
    "    Create an AutoDock configuration file based on ligand data.\n",
    "\n",
    "    Args:\n",
    "        pdb_file (str): Path to the protein PDB file.\n",
    "        output_dir (str): Directory to save the config file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Paths to the generated config files.\n",
    "    \"\"\"\n",
    "    # Extract protein name from PDB file\n",
    "    protein_name = os.path.splitext(os.path.basename(pdb_file))[0]\n",
    "\n",
    "    # Compute ligand centers and diameters\n",
    "    ligand_centers = calculate_ligand_centers(pdb_file)\n",
    "    ligand_diameters = calculate_ligand_diameter(pdb_file)\n",
    "\n",
    "    # Compute grid sizes\n",
    "    grid_sizes = {lig_id: calculate_grid_size_ligand(diameter) for lig_id, diameter in ligand_diameters.items()}\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    config_files = {}\n",
    "\n",
    "    for lig_id, ligand_center in ligand_centers.items():\n",
    "        grid_size = grid_sizes[lig_id]\n",
    "        # Define config file path\n",
    "        config_file = os.path.join(output_dir, f\"config_{protein_name}_ligand_{lig_id}.txt\")\n",
    "        with open(config_file, \"w\") as f:\n",
    "            f.write(f\"center_x = {ligand_center[0]}\\n\")\n",
    "            f.write(f\"center_y = {ligand_center[1]}\\n\")\n",
    "            f.write(f\"center_z = {ligand_center[2]}\\n\")\n",
    "            f.write(f\"size_x = {grid_size}\\n\")\n",
    "            f.write(f\"size_y = {grid_size}\\n\")\n",
    "            f.write(f\"size_z = {grid_size}\\n\")\n",
    "            f.write(\"exhaustiveness = 8\\n\")\n",
    "            f.write(\"num_modes = 20\\n\")\n",
    "        \n",
    "        config_files[lig_id] = config_file\n",
    "\n",
    "    print(f\"✅ Config files created: {config_files}\")\n",
    "    \n",
    "    return config_files\n",
    "    \n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Config file created: /Users/nicha/dev/Protein-preparation-pipeline/notebooks/rmsd_calc/config_3hvc_pocket_1.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/nicha/dev/Protein-preparation-pipeline/notebooks/rmsd_calc/config_3hvc_pocket_1.txt'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create config file from the prank output\n",
    "residues_file = \"/Users/nicha/dev/p2rank/distro/test_output/predict_3hvc_stripped/3hvc_stripped.pdb_residues.csv\"\n",
    "pocket_file = \"/Users/nicha/dev/p2rank/distro/test_output/predict_3hvc_stripped/3hvc_stripped.pdb_predictions.csv\"\n",
    "pdb_file = data_path + \"/3hvc.pdb\"\n",
    "pocket_id = 1\n",
    "\n",
    "result = calculate_pocket_data(residues_file, pocket_file, pdb_file, pocket_id)\n",
    "\n",
    "create_config_pocket_based(residues_file, pocket_file, pdb_file, pocket_id, \"/Users/nicha/dev/Protein-preparation-pipeline/notebooks/rmsd_calc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Config file created: /Users/nicha/dev/Protein-preparation-pipeline/notebooks/rmsd_calc/config_3hvc_pocket_1.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/nicha/dev/Protein-preparation-pipeline/notebooks/rmsd_calc/config_3hvc_pocket_1.txt'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a config file from median clustering\n",
    "residues_file_median = \"/Users/nicha/dev/Protein-preparation-pipeline/notebooks/residues.csv\"\n",
    "pocket_file_median = \"/Users/nicha/dev/Protein-preparation-pipeline/notebooks/pockets.csv\"\n",
    "\n",
    "pocket_id = 1\n",
    "\n",
    "create_config_pocket_based(residues_file_median, pocket_file_median, pdb_file, pocket_id, \"/Users/nicha/dev/Protein-preparation-pipeline/notebooks/rmsd_calc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Config files created: {'A_GG5_361': '/Users/nicha/dev/Protein-preparation-pipeline/notebooks/rmsd_calc/config_3hvc_ligand_A_GG5_361.txt', 'A_GG5_362': '/Users/nicha/dev/Protein-preparation-pipeline/notebooks/rmsd_calc/config_3hvc_ligand_A_GG5_362.txt'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A_GG5_361': '/Users/nicha/dev/Protein-preparation-pipeline/notebooks/rmsd_calc/config_3hvc_ligand_A_GG5_361.txt',\n",
       " 'A_GG5_362': '/Users/nicha/dev/Protein-preparation-pipeline/notebooks/rmsd_calc/config_3hvc_ligand_A_GG5_362.txt'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_config_ligand_based(pdb_file, \"/Users/nicha/dev/Protein-preparation-pipeline/notebooks/rmsd_calc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get protein\n",
    "\n",
    "# import sys\n",
    "# import os\n",
    "\n",
    "# # Define the absolute path to the 'src' directory\n",
    "# src_path = \"/Users/nicha/dev/Protein-preparation-pipeline/src\"\n",
    "\n",
    "# # Add 'src' directory to Python path\n",
    "# if src_path not in sys.path:\n",
    "#     sys.path.append(src_path)\n",
    "\n",
    "# print(\"✅ 'src' directory added to sys.path\")\n",
    "\n",
    "\n",
    "# pdb_id = '3hvc'\n",
    "# from pdb_retrival.downloader import get_pdb\n",
    "# from pdb_retrival.pdbfixer import pdbfixer\n",
    "# from pdb_retrival.pdb_data_retriever import PDBDataRetriever\n",
    "\n",
    "\n",
    "# from pdbqt_preparation.extract_protein import *\n",
    "# from pdbqt_preparation.protonation import *\n",
    "# from pdbqt_preparation.main import *\n",
    "\n",
    "\n",
    "# pdb_file = get_pdb(pdb_id)\n",
    "# pdb_fixed_file = pdbfixer(pdb_file)\n",
    "\n",
    "# print(f\"✅ PDB file '{pdb_fixed_file}' downloaded and fixed.\")\n",
    "\n",
    "# # retriever = PDBDataRetriever(pdb_id)\n",
    "# #     html_content = retriever.fetch_data()\n",
    "# #     if html_content:\n",
    "# #         parsed_data = retriever.parse_data(html_content)\n",
    "# #         retriever.print_data_retriever(parsed_data) \n",
    "        \n",
    "# # main(pdb_fixed_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the RMDS of ligand poses of 2 different grid box\n",
    "\n",
    "\n",
    "Run this command to compute RMSD between reference (ref_ligand.pdbqt) and dock poses (dock_ligand.pdbqt):\n",
    "\n",
    "`obabel ref_ligand.pdbqt dock_ligand.pdbqt --align -xr -O rmsd_output.sdf`\n",
    "\n",
    "To get RMSD in the terminal:\n",
    "\n",
    "`obabel ref_ligand.pdbqt dock_ligand.pdbqt --align -xr --rmsd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "# Exit on errors\n",
    "set -e\n",
    "\n",
    "# input path\n",
    "input_folder=/Users/nicha/dev/Protein-preparation-pipeline/notebooks/rmsd_calc\n",
    "\n",
    "mkdir -p $input_folder\n",
    "\n",
    "\n",
    "\n",
    "# Define file paths\n",
    "VINA_EXEC=\"vina\"  # Path to AutoDock Vina executable (Ensure it is installed & in PATH)\n",
    "REF_LIGAND=\"true_ligand.pdb\"  # Reference ligand with known binding pose\n",
    "LIGAND=\"ligand.pdbqt\"  # Input ligand for docking\n",
    "RECEPTOR=\"receptor.pdbqt\"  # Input receptor for docking\n",
    "CONFIG1=\"config_3hvc_pocket_1_medc.txt\"  # First docking config file\n",
    "CONFIG2=\"config_3hvc_pocket_1_prank.txt\"  # Second docking config file\n",
    "OUT_LIGAND1=\"docked_ligand1.pdbqt\"  # Output for first docking\n",
    "OUT_LIGAND2=\"docked_ligand2.pdbqt\"  # Output for second docking\n",
    "CONVERTED1=\"docked_ligand1.pdb\"  # Converted PDB file from first docking\n",
    "CONVERTED2=\"docked_ligand2.pdb\"  # Converted PDB file from second docking\n",
    "\n",
    "# Step 1: Run AutoDock Vina for each configuration\n",
    "echo \"🔹 Running Vina with Config 1...\"\n",
    "$VINA_EXEC --receptor $RECEPTOR --ligand $LIGAND --config $CONFIG1 --out $OUT_LIGAND1\n",
    "\n",
    "echo \"🔹 Running Vina with Config 2...\"\n",
    "$VINA_EXEC --receptor $RECEPTOR --ligand $LIGAND --config $CONFIG2 --out $OUT_LIGAND2\n",
    "\n",
    "# Step 2: Convert PDBQT to PDB (extract first pose)\n",
    "echo \"🔹 Extracting first pose from docked ligands...\"\n",
    "obabel $OUT_LIGAND1 -O $CONVERTED1 --gen3d\n",
    "obabel $OUT_LIGAND2 -O $CONVERTED2 --gen3d\n",
    "\n",
    "# Step 3: Calculate RMSD between reference and docked poses\n",
    "echo \"🔹 Calculating RMSD between reference and docked poses...\"\n",
    "RMSD1=$(obabel $REF_LIGAND $CONVERTED1 --align -xr --rmsd | awk '{print $NF}')\n",
    "RMSD2=$(obabel $REF_LIGAND $CONVERTED2 --align -xr --rmsd | awk '{print $NF}')\n",
    "\n",
    "# Step 4: Output results\n",
    "echo \"✅ RMSD Results:\"\n",
    "echo \"  - RMSD (Config 1 vs Reference): $RMSD1 Å\"\n",
    "echo \"  - RMSD (Config 2 vs Reference): $RMSD2 Å\"\n",
    "\n",
    "# Save results to a file\n",
    "echo -e \"Config\\tRMSD (Å)\" > rmsd_results.txt\n",
    "echo -e \"Config1\\t$RMSD1\" >> rmsd_results.txt\n",
    "echo -e \"Config2\\t$RMSD2\" >> rmsd_results.txt\n",
    "\n",
    "echo \"✅ RMSD results saved to rmsd_results.txt\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein_pp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
